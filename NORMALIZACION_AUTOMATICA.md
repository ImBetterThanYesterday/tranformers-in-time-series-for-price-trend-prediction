# NormalizaciÃ³n AutomÃ¡tica de Datos Crudos

## ðŸ“‹ Resumen

Se implementÃ³ un sistema **inteligente** que detecta y normaliza automÃ¡ticamente datos crudos (sin procesar) al cargarlos en Streamlit.

### âœ¨ CaracterÃ­sticas Principales

1. **DetecciÃ³n AutomÃ¡tica**: El sistema detecta si los datos estÃ¡n crudos o ya normalizados
2. **NormalizaciÃ³n Z-Score**: Aplica normalizaciÃ³n automÃ¡ticamente cuando es necesario
3. **Soporte Multi-Formato**: Acepta archivos CSV y NPY
4. **Transparencia**: Muestra al usuario quÃ© procesamiento se aplicÃ³

---

## ðŸ”§ Componentes Implementados

### 1. Script de CreaciÃ³n: `create_raw_examples.py`

**PropÃ³sito**: Extrae ejemplos del CSV original y los guarda **sin normalizar**.

**Salida**:
- `data/BTC/raw_examples/raw_example_N.csv` - Con timestamp
- `data/BTC/raw_examples/raw_example_N.npy` - Solo LOB (128, 40)
- `metadata.json` - InformaciÃ³n detallada
- `README.md` - DocumentaciÃ³n

**Uso**:
```bash
python3 create_raw_examples.py
```

**Resultado**: 7 ejemplos distribuidos uniformemente a lo largo del dataset

---

### 2. Funciones de NormalizaciÃ³n en `app.py`

#### `normalize_raw_data(data)`
Aplica Z-score normalization:
```python
# Precios (columnas pares)
df[col] = (df[col] - mean_prices) / std_prices

# VolÃºmenes (columnas impares)
df[col] = (df[col] - mean_volumes) / std_volumes
```

#### `is_data_normalized(data)`
Detecta automÃ¡ticamente el tipo de datos:
- **Raw (crudo)**: `mean > 100` (precios BTC ~17000-21000)
- **Normalized**: `mean â‰ˆ 0` y `std â‰ˆ 1`
- **Unknown**: Caso ambiguo

#### `load_data(filepath)`
Carga datos y normaliza automÃ¡ticamente si es necesario:
1. Lee archivo CSV o NPY
2. Verifica shape (128, 40)
3. Detecta si estÃ¡ normalizado
4. Normaliza si es necesario
5. Muestra mensaje informativo al usuario

---

## ðŸŽ¯ Flujo de Trabajo

### Caso 1: Datos Preprocesados
```
Usuario selecciona â†’ "ðŸ“¦ Preprocesados"
â†“
Carga example_1.npy
â†“
Sistema detecta: "Ya normalizados"
â†“
âœ… Listo para inferencia
```

### Caso 2: Datos Crudos (NPY)
```
Usuario selecciona â†’ "ðŸ“„ Crudos (CSV/NPY)"
â†“
Carga raw_example_1.npy
â†“
Sistema detecta: "Datos crudos" (mean=8593.41)
â†“
ðŸ”„ Aplica normalizaciÃ³n Z-score
â†“
âœ… Normalizado (meanâ‰ˆ0, stdâ‰ˆ1)
â†“
Listo para inferencia
```

### Caso 3: Datos Crudos (CSV)
```
Usuario selecciona â†’ "ðŸ“„ Crudos (CSV/NPY)"
â†“
Carga raw_example_1.csv
â†“
Sistema:
  1. Lee CSV
  2. Elimina columna 'timestamp'
  3. Detecta: "Datos crudos"
  4. Aplica normalizaciÃ³n
â†“
âœ… Listo para inferencia
```

---

## ðŸ“Š ComparaciÃ³n: Crudo vs Normalizado

| Aspecto | Crudo (Raw) | Normalizado |
|---------|-------------|-------------|
| **Precios BTC** | 17181.6, 17181.5, ... | -0.938, -0.941, ... |
| **VolÃºmenes** | 23.371, 0.746, ... | 1.234, -0.456, ... |
| **Mean** | ~8500 - 10600 | â‰ˆ 0.0 |
| **Std** | ~8500 - 10600 | â‰ˆ 1.0 |
| **Legibilidad** | âœ… Alta (valores reales) | âŒ Baja (Z-scores) |
| **Uso Directo** | âŒ No (requiere normalizaciÃ³n) | âœ… SÃ­ |
| **Formato** | CSV o NPY | NPY |

---

## ðŸ–¥ï¸ Interfaz de Streamlit

### Selector de Fuente
```
â—‹ ðŸ“¦ Preprocesados  
â—‹ ðŸ“„ Crudos (CSV/NPY)
```

### Mensajes Informativos

#### Al cargar datos crudos:
```
â„¹ï¸ Detectados datos crudos. Aplicando normalizaciÃ³n Z-score...
âœ… NormalizaciÃ³n completada (mean=0.0003, std=1.0012)
```

#### Al cargar datos ya normalizados:
```
âœ… Datos ya normalizados (mean=-0.0002, std=0.9998)
```

#### Al subir archivo:
```
Upload: *.npy o *.csv
```

---

## ðŸ“‚ Estructura de Archivos

```
data/BTC/
â”œâ”€â”€ individual_examples/          # Preprocesados (normalizados)
â”‚   â”œâ”€â”€ example_1.npy
â”‚   â”œâ”€â”€ example_2.npy
â”‚   â””â”€â”€ ...
â”‚
â”œâ”€â”€ raw_examples/                 # Crudos (sin normalizar)
â”‚   â”œâ”€â”€ raw_example_1.csv         # Con timestamp
â”‚   â”œâ”€â”€ raw_example_1.npy         # Solo LOB
â”‚   â”œâ”€â”€ raw_example_2.csv
â”‚   â”œâ”€â”€ raw_example_2.npy
â”‚   â”œâ”€â”€ ...
â”‚   â”œâ”€â”€ metadata.json
â”‚   â””â”€â”€ README.md
â”‚
â””â”€â”€ original_source/
    â””â”€â”€ 1-09-1-20.csv             # CSV original completo
```

---

## ðŸ§ª ValidaciÃ³n

### Verificar que la normalizaciÃ³n funciona:

```python
import numpy as np

# Cargar ejemplo crudo
raw = np.load('data/BTC/raw_examples/raw_example_1.npy')
print(f"Raw: mean={raw.mean():.2f}, std={raw.std():.2f}")
# Output: Raw: mean=8593.41, std=8589.24

# Cargar desde Streamlit (ya normalizado)
# meanâ‰ˆ0.0, stdâ‰ˆ1.0
```

### Verificar archivos CSV:

```python
import pandas as pd

df = pd.read_csv('data/BTC/raw_examples/raw_example_1.csv')
print(df.head())
```

**Output**:
```
   timestamp     sell1  vsell1     buy1  vbuy1  ...
0  1673302660926  17181.6  23.371  17181.5  0.746  ...
1  1673302661175  17181.6  23.371  17181.5  0.746  ...
```

---

## âœ… Ventajas del Sistema

### 1. **Flexibilidad**
- Trabaja con datos crudos y normalizados
- Soporta CSV y NPY
- DetecciÃ³n automÃ¡tica

### 2. **Transparencia**
- Usuario ve valores reales en CSV
- Sistema muestra quÃ© procesamiento aplica
- EstadÃ­sticas antes y despuÃ©s

### 3. **Facilidad de Uso**
- No requiere pre-procesamiento manual
- Upload directo de archivos
- NormalizaciÃ³n invisible al usuario

### 4. **Debugging**
- CSV legible para inspecciÃ³n manual
- Metadata detallado
- EstadÃ­sticas raw disponibles

### 5. **Portabilidad**
- CSV es formato universal
- No depende de pre-procesamiento previo
- FÃ¡cil de compartir

---

## ðŸš€ Uso Completo

### Paso 1: Crear ejemplos crudos
```bash
python3 create_raw_examples.py
```

### Paso 2: Ejecutar Streamlit
```bash
# Local
streamlit run app.py

# Docker
docker-compose up -d
```

### Paso 3: En la interfaz
1. Seleccionar "ðŸ“„ Crudos (CSV/NPY)"
2. Elegir `raw_example_1.csv` o `raw_example_1.npy`
3. Click "ðŸ”„ Cargar"
4. Ver mensaje: "ðŸ”„ Detectados datos crudos..."
5. Sistema normaliza automÃ¡ticamente
6. Hacer predicciÃ³n normalmente

---

## ðŸ“Š Ejemplo de Salida

### Al cargar `raw_example_1.csv`:

```
ðŸ”„ Detectados datos crudos. Aplicando normalizaciÃ³n Z-score...

EstadÃ­sticas originales:
  - Mean: 8593.41
  - Std: 8589.24
  - Min: 0.00
  - Max: 17186.40

âœ… NormalizaciÃ³n completada
  - Mean: 0.0003
  - Std: 1.0012
  - Min: -0.9987
  - Max: 0.9998
```

### PredicciÃ³n:

```
ðŸŽ¯ PredicciÃ³n: DOWN (81.3%)

Probabilidades:
  â–¼ DOWN:  81.3%
  â€” HOLD:  12.4%
  â–² UP:     6.3%
```

---

## ðŸ” Detalles TÃ©cnicos

### Z-Score Normalization

**FÃ³rmula**:
```
x_norm = (x - Î¼) / Ïƒ
```

**AplicaciÃ³n**:
- **Precios** (columnas 0, 2, 4, ..., 38): Usan Î¼_prices y Ïƒ_prices
- **VolÃºmenes** (columnas 1, 3, 5, ..., 39): Usan Î¼_volumes y Ïƒ_volumes

**Resultado**:
- Media â‰ˆ 0
- DesviaciÃ³n estÃ¡ndar â‰ˆ 1
- Preserva la distribuciÃ³n original
- Facilita el aprendizaje del modelo

### DetecciÃ³n de Datos

**HeurÃ­stica**:
```python
mean = abs(data.mean())
std = data.std()

if mean > 100:          # Valores reales de BTC
    return "raw"
elif mean < 1 and 0.5 < std < 2:  # Z-scores
    return "normalized"
else:
    return "unknown"
```

---

## ðŸ“ Archivos Modificados

1. **`create_raw_examples.py`** (nuevo)
   - Extrae ejemplos crudos del CSV
   - Guarda en formato CSV y NPY
   - Sin normalizaciÃ³n

2. **`app.py`**
   - `normalize_raw_data()`: Nueva funciÃ³n
   - `is_data_normalized()`: Nueva funciÃ³n
   - `load_data()`: Modificada para soportar CSV y normalizaciÃ³n automÃ¡tica
   - Selector de fuente actualizado
   - File uploader acepta CSV y NPY

3. **`data/BTC/raw_examples/`** (nuevo directorio)
   - 7 ejemplos CSV
   - 7 ejemplos NPY
   - Metadata
   - README

---

## ðŸŽ“ ConclusiÃ³n

El sistema implementado permite:

âœ… Trabajar con datos en **formato crudo** (valores reales)  
âœ… **NormalizaciÃ³n automÃ¡tica** sin intervenciÃ³n del usuario  
âœ… Soporte para **CSV y NPY**  
âœ… **Transparencia** en el procesamiento  
âœ… **Flexibilidad** para diferentes fuentes de datos  

El usuario solo necesita:
1. Seleccionar un archivo (CSV o NPY)
2. El sistema hace el resto automÃ¡ticamente

---

*ImplementaciÃ³n completada: 2024-11-16*

