# üìà TLOB: Predicci√≥n de Tendencias con Transformers en Limit Order Book

> **Implementaci√≥n del modelo TLOB (Transformer for Limit Order Book) con despliegue Docker y visualizaci√≥n Streamlit para predicci√≥n de tendencias de precios en Bitcoin**

[![Python](https://img.shields.io/badge/Python-3.12+-blue.svg)](https://www.python.org/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.0+-red.svg)](https://pytorch.org/)
[![Streamlit](https://img.shields.io/badge/Streamlit-1.28+-FF4B4B.svg)](https://streamlit.io/)
[![Docker](https://img.shields.io/badge/Docker-Ready-2496ED.svg)](https://www.docker.com/)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)

---

## üìã Tabla de Contenidos

1. [Art√≠culo Base](#-art√≠culo-base)
2. [Descripci√≥n del Modelo](#-descripci√≥n-del-modelo)
3. [Resumen Te√≥rico de la Arquitectura](#-resumen-te√≥rico-de-la-arquitectura)
4. [Mecanismo de Atenci√≥n (Q, K, V)](#-mecanismo-de-atenci√≥n-q-k-v)
5. [Pasos para Ejecutar el Proyecto](#-pasos-para-ejecutar-el-proyecto)
6. [Carga de Pesos Preentrenados](#-carga-de-pesos-preentrenados)
7. [Proceso de Inferencia](#-proceso-de-inferencia)
8. [Estructura del Repositorio](#-estructura-del-repositorio)
9. [Documentaci√≥n Adicional](#-documentaci√≥n-adicional)
10. [Referencias](#-referencias)

---

## üìÑ Art√≠culo Base

**T√≠tulo:** *"TLOB: A Novel Transformer Model with Dual Attention for Stock Price Trend Prediction with Limit Order Book Data"*

**Autores:** 
- Leonardo Berti (Sapienza University of Rome)
- Gjergji Kasneci (Technical University of Munich)

**Publicaci√≥n:** arXiv:2502.15757, 2025

**Repositorio Original:** [https://github.com/LeonardoBerti00/TLOB](https://github.com/LeonardoBerti00/TLOB)

**Paper:** [https://arxiv.org/pdf/2502.15757](https://arxiv.org/pdf/2502.15757)

### Citaci√≥n

```bibtex
@article{berti2025tlob,
  title={TLOB: A Novel Transformer Model with Dual Attention for Stock Price Trend Prediction with Limit Order Book Data},
  author={Berti, Leonardo and Kasneci, Gjergji},
  journal={arXiv preprint arXiv:2502.15757},
  year={2025}
}
```

### Abstract del Paper

El modelo TLOB introduce una arquitectura Transformer especializada para la predicci√≥n de tendencias de precios utilizando datos del Limit Order Book (LOB). A diferencia de modelos anteriores basados en CNN y LSTM, TLOB utiliza un mecanismo de **atenci√≥n dual** (spatial y temporal) que captura relaciones entre features y evoluci√≥n temporal de manera m√°s efectiva. El modelo incorpora **BiN (Batch Independent Normalization)** para funcionar eficientemente con batch_size=1 en producci√≥n, y un **nuevo m√©todo de etiquetado sin sesgo de horizonte** que mejora la consistencia entre diferentes horizontes de predicci√≥n.

---

## üéØ Descripci√≥n del Modelo

### ¬øQu√© es TLOB?

**TLOB (Transformer for Limit Order Book)** es un modelo de aprendizaje profundo dise√±ado espec√≠ficamente para predecir tendencias de precios en mercados financieros usando datos del **Limit Order Book**.

### ¬øQu√© es un Limit Order Book?

El Limit Order Book es una estructura de datos en tiempo real que contiene:
- **Ask (Sell) Orders**: √ìrdenes de venta ordenadas por precio (menor a mayor)
- **Bid (Buy) Orders**: √ìrdenes de compra ordenadas por precio (mayor a menor)

**Ejemplo:**
```
Nivel  |  ASK Price  |  ASK Volume  |  BID Price  |  BID Volume
-------|-------------|--------------|-------------|-------------
  1    |  $50,100    |    2.5 BTC   |  $50,095    |   3.2 BTC
  2    |  $50,105    |    1.8 BTC   |  $50,090    |   2.1 BTC
  ...  |    ...      |     ...      |    ...      |    ...
  10   |  $50,150    |    5.0 BTC   |  $50,050    |   4.5 BTC
```

### Principales Innovaciones del Modelo

#### 1. **Dual Attention Mechanism** üîç
El modelo aplica atenci√≥n en DOS dimensiones:

- **Feature Attention (Espacial):**
  - ¬øQu√© niveles del LOB son m√°s importantes?
  - Ejemplo: El primer nivel (best bid/ask) t√≠picamente tiene m√°s peso

- **Temporal Attention:**
  - ¬øQu√© timesteps del pasado son m√°s relevantes?
  - Ejemplo: Eventos recientes vs. patrones hist√≥ricos

#### 2. **BiN (Batch-Instance Normalization)** üìä
Normalizaci√≥n h√≠brida que combina:
```python
BiN(x) = 0.5 * BatchNorm(x) + 0.5 * InstanceNorm(x)
```

**Ventajas:**
- Estabiliza el entrenamiento con datos financieros vol√°tiles
- Preserva informaci√≥n tanto a nivel de batch como de instancia individual

#### 3. **Arquitectura Eficiente** ‚ö°
- **Par√°metros totales:** ~1.1M (compacto pero potente)
- **Inferencia r√°pida:** ~50ms por predicci√≥n en CPU
- **Memoria:** ~500MB (modelo + datos)

#### 4. **Desempe√±o Superior** üèÜ
Comparado con modelos state-of-the-art:
- **F1-Score:** +3.7% en dataset FI-2010
- **Accuracy:** +1.1% en dataset Bitcoin
- **Generalizaci√≥n:** Funciona en m√∫ltiples criptomonedas y acciones

---

## üèóÔ∏è Resumen Te√≥rico de la Arquitectura

### Flujo General del Modelo

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                  INPUT: LOB Snapshot                      ‚îÇ
‚îÇ       Shape: (batch=32, seq_len=128, features=40)        ‚îÇ
‚îÇ                                                            ‚îÇ
‚îÇ  Features: [ASK_P1, ASK_V1, BID_P1, BID_V1, ... √ó10]    ‚îÇ
‚îÇ  Timesteps: 128 snapshots √ó 250ms = 32 segundos          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
  ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  STEP 1: BiN Normalization                               ‚îÇ
‚îÇ  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ                                ‚îÇ
‚îÇ  ‚Ä¢ Normaliza precios y vol√∫menes                         ‚îÇ
‚îÇ  ‚Ä¢ Combina batch + instance normalization                ‚îÇ
‚îÇ  ‚Ä¢ Output: (32, 128, 40)                                 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
               ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  STEP 2: Linear Embedding                                ‚îÇ
‚îÇ  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ                                ‚îÇ
‚îÇ  ‚Ä¢ Proyecta features a espacio latente                   ‚îÇ
‚îÇ  ‚Ä¢ 40 features ‚Üí hidden_dim (256)                        ‚îÇ
‚îÇ  ‚Ä¢ Output: (32, 128, 256)                                ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
               ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  STEP 3: Positional Encoding                             ‚îÇ
‚îÇ  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ                                ‚îÇ
‚îÇ  ‚Ä¢ A√±ade informaci√≥n temporal (posici√≥n en secuencia)    ‚îÇ
‚îÇ  ‚Ä¢ Sinusoidal o aprendible                               ‚îÇ
‚îÇ  ‚Ä¢ Output: (32, 128, 256)                                ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
               ‚Üì
              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
              ‚îÇ                     ‚îÇ
              ‚Üì                     ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  BRANCH 1:           ‚îÇ  ‚îÇ  BRANCH 2:           ‚îÇ
‚îÇ  Feature Attention   ‚îÇ  ‚îÇ  Temporal Attention  ‚îÇ
‚îÇ  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ   ‚îÇ  ‚îÇ  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ   ‚îÇ
‚îÇ                      ‚îÇ  ‚îÇ                      ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ Transformer    ‚îÇ ‚îÇ  ‚îÇ  ‚îÇ Transformer    ‚îÇ ‚îÇ
‚îÇ  ‚îÇ Layer 1        ‚îÇ ‚îÇ  ‚îÇ  ‚îÇ Layer 1        ‚îÇ ‚îÇ
‚îÇ  ‚îÇ (256 √ó 128)    ‚îÇ ‚îÇ  ‚îÇ  ‚îÇ (128 √ó 256)    ‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îÇ          ‚Üì          ‚îÇ  ‚îÇ          ‚Üì          ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ Transformer    ‚îÇ ‚îÇ  ‚îÇ  ‚îÇ Transformer    ‚îÇ ‚îÇ
‚îÇ  ‚îÇ Layer 2        ‚îÇ ‚îÇ  ‚îÇ  ‚îÇ Layer 2        ‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îÇ          ‚Üì          ‚îÇ  ‚îÇ          ‚Üì          ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ Transformer    ‚îÇ ‚îÇ  ‚îÇ  ‚îÇ Transformer    ‚îÇ ‚îÇ
‚îÇ  ‚îÇ Layer 3        ‚îÇ ‚îÇ  ‚îÇ  ‚îÇ Layer 3        ‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îÇ          ‚Üì          ‚îÇ  ‚îÇ          ‚Üì          ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ Transformer    ‚îÇ ‚îÇ  ‚îÇ  ‚îÇ Transformer    ‚îÇ ‚îÇ
‚îÇ  ‚îÇ Layer 4        ‚îÇ ‚îÇ  ‚îÇ  ‚îÇ Layer 4        ‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îÇ                      ‚îÇ  ‚îÇ                      ‚îÇ
‚îÇ  Output: (32,32,64) ‚îÇ  ‚îÇ  Output: (32,32,64) ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
           ‚îÇ                         ‚îÇ
           ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  STEP 4: Concatenate & Flatten                           ‚îÇ
‚îÇ  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ                        ‚îÇ
‚îÇ  ‚Ä¢ Combina ambas ramas                                   ‚îÇ
‚îÇ  ‚Ä¢ Flatten: (32, 32, 64) + (32, 32, 64) ‚Üí (32, 4096)    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  STEP 5: Final MLP                                       ‚îÇ
‚îÇ  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ                                       ‚îÇ
‚îÇ  ‚Ä¢ Linear(4096 ‚Üí 1024) + GELU                           ‚îÇ
‚îÇ  ‚Ä¢ Linear(1024 ‚Üí 256) + GELU                            ‚îÇ
‚îÇ  ‚Ä¢ Linear(256 ‚Üí 3)                                      ‚îÇ
‚îÇ  ‚Ä¢ Softmax                                               ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  OUTPUT: Predicci√≥n de Tendencia                         ‚îÇ
‚îÇ  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ                      ‚îÇ
‚îÇ  Shape: (32, 3)                                          ‚îÇ
‚îÇ                                                           ‚îÇ
‚îÇ  Clases:                                                 ‚îÇ
‚îÇ    0: DOWN       (precio bajar√°)                         ‚îÇ
‚îÇ    1: STATIONARY (precio estable)                        ‚îÇ
‚îÇ    2: UP         (precio subir√°)                         ‚îÇ
‚îÇ                                                           ‚îÇ
‚îÇ  Ejemplo: [0.10, 0.15, 0.75] ‚Üí Predicci√≥n: UP (75%)    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Componentes Clave

#### TransformerLayer

Cada capa Transformer contiene:

```python
class TransformerLayer(nn.Module):
    def __init__(self, hidden_dim, num_heads):
        # 1. Layer Normalization
        self.norm = nn.LayerNorm(hidden_dim)
        
        # 2. Multi-Head Attention
        self.qkv = ComputeQKV(hidden_dim, num_heads)
        self.attention = nn.MultiheadAttention(...)
        
        # 3. Feed-Forward MLP
        self.mlp = MLP(hidden_dim, hidden_dim*4, final_dim)
        
    def forward(self, x):
        # Residual connection
        res = x
        
        # Atenci√≥n
        q, k, v = self.qkv(x)
        x, att = self.attention(q, k, v)
        
        # Skip connection + Norm
        x = self.norm(x + res)
        
        # MLP + Skip connection
        x = self.mlp(x) + x
        
        return x, att
```

---

## üîç Mecanismo de Atenci√≥n (Q, K, V)

### ¬øQu√© son Q, K, V?

El mecanismo de atenci√≥n se basa en tres proyecciones de los datos de entrada:

- **Q (Queries)**: "¬øQu√© estoy buscando?"
- **K (Keys)**: "¬øQu√© informaci√≥n est√° disponible?"
- **V (Values)**: "¬øCu√°l es el contenido real?"

### Generaci√≥n de Q, K, V en TLOB

```python
class ComputeQKV(nn.Module):
    def __init__(self, hidden_dim: int, num_heads: int):
        super().__init__()
        self.q = nn.Linear(hidden_dim, hidden_dim * num_heads)
        self.k = nn.Linear(hidden_dim, hidden_dim * num_heads)
        self.v = nn.Linear(hidden_dim, hidden_dim * num_heads)
        
    def forward(self, x):
        # x: (batch, seq_len, hidden_dim)
        q = self.q(x)  # Queries
        k = self.k(x)  # Keys
        v = self.v(x)  # Values
        return q, k, v
```

### Proceso Detallado

#### 1Ô∏è‚É£ Input Embeddings

```
Input: (batch=32, seq_len=128, features=40)
         ‚Üì BiN + Embedding
Embedded: (32, 128, 256)
```

#### 2Ô∏è‚É£ Proyecciones Lineales

Cada timestep pasa por 3 transformaciones lineales independientes:

```python
# Para cada posici√≥n t:
Q[t] = W_q @ x[t] + b_q  # Shape: (256,)
K[t] = W_k @ x[t] + b_k  # Shape: (256,)
V[t] = W_v @ x[t] + b_v  # Shape: (256,)
```

**Matrices aprendibles:**
- `W_q`, `W_k`, `W_v`: Pesos de las proyecciones lineales
- Se aprenden durante el entrenamiento

#### 3Ô∏è‚É£ Multi-Head Attention

Las proyecciones se dividen en m√∫ltiples "cabezas":

```
num_heads = 8
hidden_dim = 256
head_dim = hidden_dim / num_heads = 32

Q: (32, 128, 256) ‚Üí Reshape ‚Üí (32, 8, 128, 32)
K: (32, 128, 256) ‚Üí Reshape ‚Üí (32, 8, 128, 32)
V: (32, 128, 256) ‚Üí Reshape ‚Üí (32, 8, 128, 32)
```

**¬øPor qu√© m√∫ltiples cabezas?**
- Cada cabeza aprende diferentes aspectos de los datos
- Cabeza 1: Puede enfocarse en el spread (diferencia bid-ask)
- Cabeza 2: Puede enfocarse en el volumen
- Cabeza 3: Puede enfocarse en cambios temporales

#### 4Ô∏è‚É£ C√°lculo de Atenci√≥n

**F√≥rmula Scaled Dot-Product Attention:**

```
Attention(Q, K, V) = softmax(Q @ K^T / ‚àöd_k) @ V
```

**Paso a paso:**

```python
# 1. Scores de atenci√≥n (producto punto)
scores = Q @ K.transpose(-2, -1)  # (32, 8, 128, 128)
# scores[i, h, t, s] = cu√°nto el timestep t "atiende" al timestep s

# 2. Scaling (para estabilidad num√©rica)
d_k = 32  # head_dim
scores = scores / math.sqrt(d_k)

# 3. Softmax (normalizar a pesos que sumen 1)
attention_weights = softmax(scores, dim=-1)  # (32, 8, 128, 128)
# attention_weights[i, h, t, :].sum() == 1.0

# 4. Weighted sum de Values
output = attention_weights @ V  # (32, 8, 128, 32)
```

#### 5Ô∏è‚É£ Interpretaci√≥n de los Pesos de Atenci√≥n

```python
# Ejemplo: Predicci√≥n en el timestep t=127
attention_weights[0, 0, 127, :]  # Primera cabeza, √∫ltimo timestep

# Resultado t√≠pico:
# [0.001, 0.002, ..., 0.050, 0.080, 0.150]
#   ‚Üë                  ‚Üë      ‚Üë       ‚Üë
#   timesteps         t=100  t=120  t=126
#   antiguos          (medio) (reciente) (muy reciente)
```

**Interpretaci√≥n:**
- Pesos altos en timesteps recientes ‚Üí Considera eventos inmediatos
- Pesos bajos en timesteps antiguos ‚Üí Menos relevantes para la predicci√≥n actual

### Visualizaci√≥n de Atenci√≥n

La aplicaci√≥n Streamlit incluye visualizaci√≥n de pesos de atenci√≥n:

```python
# En app.py
att_weights = model.attention_weights  # (num_heads, seq_len, seq_len)

# Heatmap de atenci√≥n
plt.imshow(att_weights[0, :, :], cmap='viridis')
plt.xlabel('Key Position (timestep)')
plt.ylabel('Query Position (timestep)')
plt.title('Attention Weights - Head 0')
```

**üìñ Para m√°s detalles:** Ver [`docs/MECANISMO_ATENCION_QKV.md`](docs/MECANISMO_ATENCION_QKV.md)

---

## üöÄ Pasos para Ejecutar el Proyecto

### Requisitos Previos

```bash
# Sistema operativo: Linux, macOS, o Windows (con WSL2)
# Docker Desktop 20.10+ (incluye Docker Compose)
# RAM: 4GB+ disponible
# Disco: 10GB+ libre
```

### ‚ö° M√©todo R√°pido: Docker Compose (Recomendado)

**Solo 3 comandos para ejecutar todo el proyecto:**

```bash
# 1. Clonar repositorio
git clone https://github.com/tu-usuario/tlob-prediction.git
cd tlob-prediction

# 2. Levantar aplicaci√≥n con un solo comando
docker-compose up -d

# ‚úÖ ¬°Listo! La app estar√° disponible en http://localhost:8501
```

#### Comandos √ötiles

```bash
# Ver logs en tiempo real
docker-compose logs -f

# Verificar estado
docker-compose ps

# Detener aplicaci√≥n
docker-compose down

# Reconstruir despu√©s de cambios
docker-compose up -d --build
```

**üìñ Para m√°s detalles:** Ver [`docs/INFERENCIA_Y_DESPLIEGUE_DOCKER_STREAMLIT.md`](docs/INFERENCIA_Y_DESPLIEGUE_DOCKER_STREAMLIT.md)

---

### Opci√≥n 2: Instalaci√≥n Local üíª

#### 1. Clonar el Repositorio

```bash
git clone https://github.com/tu-usuario/tlob-prediction.git
cd tlob-prediction
```

#### 2. Crear Entorno Virtual

```bash
# Crear entorno virtual
python3.12 -m venv venv

# Activar entorno
# En Linux/macOS:
source venv/bin/activate
# En Windows:
venv\Scripts\activate
```

#### 3. Instalar Dependencias

```bash
# Actualizar pip
pip install --upgrade pip

# Instalar dependencias
pip install -r requirements.txt

# Verificar instalaci√≥n
python -c "import torch; import streamlit; print('‚úì OK')"
```

#### 4. Ejecutar Streamlit

```bash
# Ejecutar aplicaci√≥n
streamlit run app.py

# La aplicaci√≥n se abrir√° autom√°ticamente en:
# http://localhost:8501
```

---

## üíæ Carga de Pesos Preentrenados

### Ubicaci√≥n de los Checkpoints

Los pesos preentrenados se encuentran en:

```
src/data/checkpoints/
‚îú‚îÄ‚îÄ TLOB/
‚îÇ   ‚îî‚îÄ‚îÄ BTC_seq_size_128_horizon_10_seed_42/
‚îÇ       ‚îú‚îÄ‚îÄ pt/
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ model.pt          # ‚≠ê Modelo PyTorch
‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ config.json       # Configuraci√≥n del modelo
‚îÇ       ‚îî‚îÄ‚îÄ predictions.npy       # Predicciones de ejemplo
‚îú‚îÄ‚îÄ DEEPLOB/
‚îÇ   ‚îî‚îÄ‚îÄ BTC_seq_size_100_horizon_10_seed_42/...
‚îú‚îÄ‚îÄ MLPLOB/
‚îÇ   ‚îî‚îÄ‚îÄ BTC_seq_size_384_horizon_10_seed_42/...
‚îî‚îÄ‚îÄ BINCTABL/
    ‚îî‚îÄ‚îÄ BTC_seq_size_10_horizon_10_seed_42/...
```

### Proceso de Carga en el C√≥digo

#### 1. Definici√≥n de Rutas (config/constants.py)

```python
import torch
from pathlib import Path

# Ruta base
DATA_DIR = Path("src/data")
CHECKPOINT_DIR = DATA_DIR / "checkpoints"

# Checkpoint del modelo TLOB
TLOB_CHECKPOINT = CHECKPOINT_DIR / "TLOB" / "BTC_seq_size_128_horizon_10_seed_42" / "pt" / "model.pt"

# Device (CPU o GPU)
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
```

#### 2. Inicializaci√≥n del Modelo (models/tlob.py)

```python
from models.tlob import TLOB
import torch

# Configuraci√≥n del modelo (debe coincidir con el entrenamiento)
model_config = {
    'hidden_dim': 40,          # Dimensi√≥n del espacio latente
    'num_layers': 4,           # N√∫mero de capas Transformer
    'seq_size': 128,           # Longitud de secuencia
    'num_features': 40,        # N√∫mero de features del LOB
    'num_heads': 8,            # Cabezas de atenci√≥n
    'is_sin_emb': True,        # Positional encoding sinusoidal
    'dataset_type': 'BTC'      # Tipo de dataset
}

# Crear instancia del modelo
model = TLOB(**model_config)
```

#### 3. Carga de Pesos (app.py)

```python
# Cargar pesos preentrenados
checkpoint_path = "src/data/checkpoints/TLOB/.../model.pt"

# Cargar state_dict
state_dict = torch.load(checkpoint_path, map_location=DEVICE)

# Aplicar pesos al modelo
model.load_state_dict(state_dict)

# Modo evaluaci√≥n (desactiva dropout, batch norm, etc.)
model.eval()

print(f"‚úì Modelo cargado desde: {checkpoint_path}")
print(f"‚úì Device: {DEVICE}")
print(f"‚úì Par√°metros totales: {sum(p.numel() for p in model.parameters()):,}")
```

### Verificaci√≥n de la Carga

```python
# Verificar que los pesos se cargaron correctamente
def verify_model_weights(model):
    """Verifica que el modelo tiene pesos v√°lidos"""
    for name, param in model.named_parameters():
        if torch.isnan(param).any():
            raise ValueError(f"NaN detectado en {name}")
        if torch.isinf(param).any():
            raise ValueError(f"Inf detectado en {name}")
    print("‚úì Todos los pesos son v√°lidos")

verify_model_weights(model)
```

### Gesti√≥n de Errores Comunes

```python
import sys

try:
    # Intentar cargar modelo
    model = TLOB(**model_config)
    state_dict = torch.load(checkpoint_path, map_location=DEVICE)
    model.load_state_dict(state_dict)
    model.eval()
    
except FileNotFoundError:
    print(f"‚ùå Error: Checkpoint no encontrado en {checkpoint_path}")
    print("‚Üí Verificar que la ruta es correcta")
    sys.exit(1)
    
except RuntimeError as e:
    print(f"‚ùå Error al cargar state_dict: {e}")
    print("‚Üí Verificar que model_config coincide con el modelo entrenado")
    sys.exit(1)
    
except Exception as e:
    print(f"‚ùå Error inesperado: {e}")
    sys.exit(1)
```

---

## üîÆ Proceso de Inferencia

### Flujo Completo

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  1. Cargar Datos     ‚îÇ  ‚Üê CSV o NPY con LOB data
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
           ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  2. Preprocesar      ‚îÇ  ‚Üê Reordenar + Normalizar
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
           ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  3. Crear Ventanas   ‚îÇ  ‚Üê Sequences de 128 timesteps
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
           ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  4. Inferencia       ‚îÇ  ‚Üê Forward pass del modelo
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
           ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  5. Post-proceso     ‚îÇ  ‚Üê Softmax + argmax
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
           ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  6. Visualizar       ‚îÇ  ‚Üê Mostrar en Streamlit
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### 1. Cargar Datos

```python
import numpy as np
import pandas as pd

# Opci√≥n A: Desde archivo NPY
data = np.load("src/data/BTC/raw_examples/raw_example_1.npy")
# Shape: (128, 42)

# Opci√≥n B: Desde archivo CSV
data = pd.read_csv("src/data/BTC/raw_examples/raw_example_1.csv")
data = data.values  # Convertir a numpy array
# Shape: (128, 42)
```

### 2. Preprocesar Datos

#### A. Reordenamiento de Columnas

El CSV original tiene columnas en orden diferente al esperado por el modelo:

```python
def reorder_columns(data):
    """
    CSV Original:
    [timestamp, datetime, BID_P1-10, BID_V1-10, ASK_P1-10, ASK_V1-10]
    
    Formato del Modelo:
    [timestamp, ASK_P1, ASK_V1, BID_P1, BID_V1, ASK_P2, ASK_V2, ...]
    """
    df = pd.DataFrame(data)
    df.columns = np.arange(42)
    
    # Reordenamiento seg√∫n preprocessing/btc.py
    new_order = [
        1,   # timestamp
        22, 23,  # ASK_P1, ASK_V1
        2, 3,    # BID_P1, BID_V1
        24, 25,  # ASK_P2, ASK_V2
        4, 5,    # BID_P2, BID_V2
        # ... hasta nivel 10
    ]
    
    df_reordered = df.loc[:, new_order]
    return df_reordered.values
```

#### B. Normalizaci√≥n Z-Score

```python
def z_score_normalize(data):
    """
    Normaliza precios y vol√∫menes por separado
    usando Z-score normalization
    """
    # Separar timestamp
    timestamp = data[:, 0]
    features = data[:, 1:]  # 40 features (sin timestamp)
    
    # Columnas de precios (pares: 0, 2, 4, ...)
    price_cols = features[:, 0::2]
    # Columnas de vol√∫menes (impares: 1, 3, 5, ...)
    volume_cols = features[:, 1::2]
    
    # Calcular estad√≠sticas
    mean_prices = price_cols.mean()
    std_prices = price_cols.std()
    mean_volumes = volume_cols.mean()
    std_volumes = volume_cols.std()
    
    # Aplicar z-score
    price_cols_norm = (price_cols - mean_prices) / std_prices
    volume_cols_norm = (volume_cols - mean_volumes) / std_volumes
    
    # Recombinar (intercalando precios y vol√∫menes)
    normalized = np.empty_like(features)
    normalized[:, 0::2] = price_cols_norm
    normalized[:, 1::2] = volume_cols_norm
    
    return normalized, (mean_prices, std_prices, mean_volumes, std_volumes)
```

#### C. Implementaci√≥n Completa

```python
from preprocessing.btc import preprocess_btc_data

# Preprocesar (reordenar + normalizar)
data_processed, stats = preprocess_btc_data(data_raw)

# data_processed shape: (128, 40)
# stats: {mean_prices, std_prices, mean_volumes, std_volumes}
```

### 3. Crear Tensor de Entrada

```python
import torch

# Convertir a tensor
input_tensor = torch.tensor(data_processed, dtype=torch.float32)

# A√±adir dimensi√≥n de batch
input_tensor = input_tensor.unsqueeze(0)  # (1, 128, 40)

# Mover a device
input_tensor = input_tensor.to(DEVICE)

print(f"Input shape: {input_tensor.shape}")
# Output: Input shape: torch.Size([1, 128, 40])
```

### 4. Inferencia

```python
# Desactivar gradientes (inferencia, no entrenamiento)
with torch.no_grad():
    # Forward pass
    output, attention_weights = model(input_tensor, store_att=True)

    # output shape: (1, 3)
    # attention_weights: dict con pesos de atenci√≥n de cada capa

# Aplicar softmax para obtener probabilidades
probabilities = torch.softmax(output, dim=1)
    
# Obtener predicci√≥n (clase con mayor probabilidad)
predicted_class = torch.argmax(probabilities, dim=1)

print(f"Probabilities: {probabilities[0].cpu().numpy()}")
# Output: Probabilities: [0.102, 0.153, 0.745]

print(f"Predicted class: {predicted_class.item()}")
# Output: Predicted class: 2 (UP)
```

### 5. Interpretaci√≥n de Resultados

```python
# Mapeo de clases
LABEL_MAP = {
    0: "DOWN",
    1: "STATIONARY",
    2: "UP"
}

# Obtener predicci√≥n legible
prediction = LABEL_MAP[predicted_class.item()]
confidence = probabilities[0, predicted_class].item() * 100

print(f"Predicci√≥n: {prediction}")
print(f"Confianza: {confidence:.1f}%")

# Output:
# Predicci√≥n: UP
# Confianza: 74.5%
```

### 6. Visualizaci√≥n en Streamlit

```python
import streamlit as st
import plotly.graph_objects as go

# Mostrar resultados
st.success(f"‚úÖ Predicci√≥n: **{prediction}**")
st.info(f"üìä Confianza: **{confidence:.1f}%**")
    
# Gr√°fico de barras con probabilidades
fig = go.Figure(data=[
    go.Bar(
        x=["DOWN", "STATIONARY", "UP"],
        y=probabilities[0].cpu().numpy() * 100,
        marker_color=['#FF4B4B', '#FFA500', '#4BFF4B']
    )
])
fig.update_layout(
    title="Probabilidades de Predicci√≥n",
    yaxis_title="Probabilidad (%)",
    yaxis_range=[0, 100]
)
    st.plotly_chart(fig)
```

### Script de Inferencia Independiente

Para ejecutar inferencia sin Streamlit:

```bash
# Inferencia de un archivo individual
python inference/inference_pytorch.py \
  --model TLOB \
  --input_file src/data/BTC/raw_examples/raw_example_1.npy \
  --output_dir results/

# Inferencia en batch
python inference/inference_pytorch.py \
  --model TLOB \
  --input_file src/data/BTC/csv_examples/csv_examples_batch.npy \
  --batch_size 32 \
  --output_dir results/
```

**üìñ Para m√°s detalles:** Ver [`docs/INFERENCIA_Y_DESPLIEGUE_DOCKER_STREAMLIT.md`](docs/INFERENCIA_Y_DESPLIEGUE_DOCKER_STREAMLIT.md)

---

## üìÇ Estructura del Repositorio

```
TLOB-main/
‚îú‚îÄ‚îÄ README.md                          # üìñ Este archivo - Gu√≠a completa
‚îú‚îÄ‚îÄ LICENSE                            # Licencia MIT
‚îú‚îÄ‚îÄ .gitignore                         # Archivos ignorados por Git
‚îÇ
‚îú‚îÄ‚îÄ app.py                             # üé® Aplicaci√≥n Streamlit (Principal)
‚îú‚îÄ‚îÄ Dockerfile                         # üê≥ Configuraci√≥n de imagen Docker
‚îú‚îÄ‚îÄ docker-compose.yml                 # üê≥ Orquestaci√≥n multi-contenedor
‚îú‚îÄ‚îÄ requirements.txt                   # üì¶ Dependencias Python con versiones
‚îÇ
‚îú‚îÄ‚îÄ .devcontainer/                     # üõ†Ô∏è Dev Container para VSCode
‚îÇ   ‚îú‚îÄ‚îÄ devcontainer.json              # Configuraci√≥n del contenedor
‚îÇ   ‚îî‚îÄ‚îÄ Dockerfile                     # Dockerfile para desarrollo
‚îÇ
‚îú‚îÄ‚îÄ src/                               # üìÇ C√≥digo fuente principal
‚îÇ   ‚îú‚îÄ‚îÄ constants.py                   # üîß Constantes del proyecto
‚îÇ   ‚îú‚îÄ‚îÄ main.py                        # üöÄ Script principal de entrenamiento
‚îÇ   ‚îú‚îÄ‚îÄ run.py                         # üèÉ Runner de experimentos
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ config/                        # ‚öôÔ∏è Configuraci√≥n
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ config.py                  # Configuraci√≥n con Hydra
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ data/                          # üìä Datos y checkpoints
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ checkpoints/               # ‚≠ê Pesos preentrenados
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ TLOB/                  # Modelos TLOB (horizonte 10/20/50/100)
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ BTC_seq_size_128_horizon_10_seed_42/
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ pt/            # Checkpoints PyTorch (.pt)
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ onnx/          # Modelos ONNX (.onnx)
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ DEEPLOB/               # Modelos DeepLOB
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ MLPLOB/                # Modelos MLPLOB
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ BINCTABL/              # Modelos BiNCTABL
‚îÇ   ‚îÇ   ‚îÇ
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ BTC/                       # Datos de Bitcoin
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ original_source/       # CSV original de Binance
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ individual_examples/   # Ejemplos preprocesados (.npy)
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ raw_examples/          # Ejemplos sin procesar (.csv, .npy)
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ models/                        # üß† Arquitecturas de modelos
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ tlob.py                    # ‚≠ê Modelo TLOB con Dual Attention
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ deeplob.py                 # Modelo DeepLOB (baseline)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ mlplob.py                  # Modelo MLPLOB
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ binctabl.py                # Modelo BiNCTABL
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ bin.py                     # BiN (Batch Independent Normalization)
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ engine.py                  # Engine de entrenamiento (Lightning)
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ preprocessing/                 # üîÑ Preprocesamiento de datos
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ btc.py                     # Procesamiento BTC/Binance
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ fi_2010.py                 # Procesamiento FI-2010
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ dataset.py                 # PyTorch Dataset personalizado
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ lobster.py                 # Formato LOBSTER
‚îÇ   ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ utils/                         # üõ†Ô∏è Utilidades
‚îÇ       ‚îú‚îÄ‚îÄ utils_data.py              # Funciones de datos y etiquetado
‚îÇ       ‚îî‚îÄ‚îÄ utils_model.py             # Funciones auxiliares de modelos
‚îÇ
‚îú‚îÄ‚îÄ inference/                         # üîÆ Scripts de inferencia
‚îÇ   ‚îú‚îÄ‚îÄ inference_pytorch.py           # Inferencia con PyTorch
‚îÇ   ‚îî‚îÄ‚îÄ create_raw_examples.py         # Generador de ejemplos raw
‚îÇ
‚îî‚îÄ‚îÄ docs/                                            # üìö Documentaci√≥n t√©cnica
    ‚îú‚îÄ‚îÄ MECANISMO_ATENCION_QKV.md                    # ‚≠ê Teor√≠a matem√°tica Q, K, V
    ‚îú‚îÄ‚îÄ INFERENCIA_Y_DESPLIEGUE_DOCKER_STREAMLIT.md  # ‚≠ê Inferencia y despliegue completo
    ‚îú‚îÄ‚îÄ INNOVACIONES_TLOB.md                         # ‚≠ê Dual Attention, BiN, etc.
    ‚îú‚îÄ‚îÄ ARQUITECTURA_COMPLETA.md                     # ‚≠ê 4 pares de Transformers
    ‚îî‚îÄ‚îÄ RESUMEN_EJECUTIVO.md                         # Resumen del proyecto
```

**Nota:** Los archivos marcados con ‚≠ê son documentos clave del proyecto.

---

## üìö Documentaci√≥n Adicional

### Documentos Clave

| Documento | Descripci√≥n |
|-----------|-------------|
| [`docs/MECANISMO_ATENCION_QKV.md`](docs/MECANISMO_ATENCION_QKV.md) | ‚≠ê **Teor√≠a matem√°tica completa del mecanismo de atenci√≥n (Q, K, V) con ejemplos paso a paso** |
| [`docs/INFERENCIA_Y_DESPLIEGUE_DOCKER_STREAMLIT.md`](docs/INFERENCIA_Y_DESPLIEGUE_DOCKER_STREAMLIT.md) | ‚≠ê **Gu√≠a completa de inferencia, preprocesamiento y despliegue con Docker/Streamlit** |
| [`docs/INNOVACIONES_TLOB.md`](docs/INNOVACIONES_TLOB.md) | ‚≠ê **Innovaciones del modelo: Dual Attention, BiN, etiquetado adaptativo** |
| [`docs/ARQUITECTURA_COMPLETA.md`](docs/ARQUITECTURA_COMPLETA.md) | ‚≠ê **Arquitectura detallada: 4 pares de Transformers explicados con dimensiones** |
| [`docs/RESUMEN_EJECUTIVO.md`](docs/RESUMEN_EJECUTIVO.md) | Resumen ejecutivo del proyecto |

### C√≥digo Comentado

Todo el c√≥digo del proyecto est√° **extensamente comentado** explicando:

- ‚úÖ C√≥mo se cargan los pesos del modelo
- ‚úÖ C√≥mo se preprocesan los datos de entrada
- ‚úÖ C√≥mo se genera la salida o inferencia
- ‚úÖ C√≥mo se integra la visualizaci√≥n en Streamlit

**Archivos clave con comentarios:**

- `app.py`: Aplicaci√≥n Streamlit (l√≠neas 1-658)
- `models/tlob.py`: Modelo TLOB (l√≠neas 1-157)
- `preprocessing/btc.py`: Preprocesamiento (l√≠neas 1-120)
- `inference/inference_pytorch.py`: Inferencia (l√≠neas 1-176)

---

## üéì Uso del Proyecto

### Caso de Uso 1: Predicci√≥n en Tiempo Real

1. Cargar datos del LOB en tiempo real
2. Preprocesar (ventana de 128 timesteps)
3. Ejecutar inferencia
4. Visualizar predicci√≥n en Streamlit

### Caso de Uso 2: An√°lisis Hist√≥rico

1. Cargar dataset hist√≥rico (CSV)
2. Crear ejemplos con `create_examples_from_csv.py`
3. Ejecutar inferencia en batch
4. Analizar resultados y m√©tricas

### Caso de Uso 3: Comparaci√≥n de Modelos

1. Cargar mismo ejemplo para m√∫ltiples modelos
2. Ejecutar inferencia con TLOB, DeepLOB, MLPLOB, BINCTABL
3. Comparar predicciones y confianza
4. Visualizar diferencias en Streamlit

---

## üî¨ Resultados y Desempe√±o

Los resultados presentados a continuaci√≥n son los reportados en el paper original (Berti & Kasneci, 2025) y demuestran el desempe√±o superior de TLOB y MLPLOB frente a modelos del estado del arte.

### Resultados en FI-2010 Benchmark

**F1-Score (%) en cuatro horizontes de predicci√≥n:**

| Modelo | h = 10 | h = 20 | h = 50 | h = 100 |
|--------|--------|--------|--------|---------|
| SVM | 35.9 | 43.2 | 49.4 | 51.2 |
| Random Forest | 48.7 | 46.3 | 51.2 | 53.9 |
| XGBoost | 62.4 | 59.6 | 65.3 | 67.6 |
| MLP | 48.2 | 44.0 | 49.0 | 51.6 |
| LSTM [39] | 66.5 | 58.8 | 66.9 | 59.4 |
| CNN [38] | 49.3 | 46.1 | 65.8 | 67.2 |
| CTABL [36] | 69.5 | 62.4 | 71.6 | 73.9 |
| DAIN-MLP [30] | 53.9 | 46.7 | 61.2 | 62.8 |
| CNNLSTM [40] | 63.5 | 49.1 | 69.2 | 71.0 |
| AXIALLOB [23] | 73.2 | 63.4 | 78.3 | 79.2 |
| DLA [18] | 79.4 | 69.3 | 87.1 | 52.2 |
| DeepLOB [45] | 71.1 | 62.4 | 75.4 | 77.6 |
| BiNCTABL [37] | 81.1 | 71.5 | 87.7 | 92.1 |
| **MLPLOB** | **81.64** | **84.88** | **91.39** | 92.62 |
| **TLOB** | 81.55 | 82.68 | 90.03 | **92.81** |

**An√°lisis:**
- TLOB y MLPLOB superan a todos los baselines con una mejora promedio de **+3.7% en F1-score**
- MLPLOB es ligeramente superior en horizontes cortos (h=10, 20)
- TLOB domina en horizontes largos (h=50, 100), demostrando su capacidad para capturar dependencias temporales de largo alcance

### Resultados en Tesla (TSLA) - NASDAQ

**F1-Score (%) en cuatro horizontes de predicci√≥n:**

| Modelo | h = 10 | h = 20 | h = 50 | h = 100 |
|--------|--------|--------|--------|---------|
| DeepLOB | 36.25 | 36.58 | 35.29 | 34.43 |
| BiNCTABL | 58.69 | 48.83 | 42.23 | 38.77 |
| MLPLOB | **60.72** | **50.25** | 38.97 | 32.95 |
| **TLOB** | 60.50 | 49.74 | **43.48** | **39.84** |

**An√°lisis:**
- Mejora promedio de **+1.3% en F1-score** sobre baselines
- Tesla presenta mayor volatilidad y complejidad que FI-2010
- TLOB muestra ventaja significativa en horizontes largos (h=50, 100)
- Performance inferior a FI-2010 refleja mayor eficiencia del mercado NASDAQ

### Resultados en Intel (INTC) - NASDAQ

**F1-Score (%) en cuatro horizontes de predicci√≥n:**

| Modelo | h = 10 | h = 20 | h = 50 | h = 100 |
|--------|--------|--------|--------|---------|
| DeepLOB | 68.13 | 63.70 | 40.3 | 30.1 |
| BiNCTABL | 72.65 | 66.57 | 53.99 | 41.08 |
| **MLPLOB** | **81.15** | **73.25** | 55.74 | 43.18 |
| **TLOB** | 80.15 | 72.75 | **62.07** | **50.14** |

**An√°lisis:**
- Mejora promedio de **+7.7% en F1-score** sobre baselines
- Intel como "small-tick stock" presenta caracter√≠sticas diferentes a Tesla
- TLOB supera significativamente a todos los modelos en horizontes largos
- Diferencia de ~7% entre MLPLOB y TLOB en h=50 y h=100 demuestra importancia de dual attention

### Resultados en Bitcoin (BTC)

**F1-Score (%) en cuatro horizontes de predicci√≥n:**

| Modelo | h = 10 | h = 20 | h = 50 | h = 100 |
|--------|--------|--------|--------|---------|
| DeepLOB | 68.07 | 57.87 | 45.13 | 37.43 |
| BiNCTABL | 73.4 | 61.34 | 47.05 | 40.59 |
| MLPLOB | 74.6 | 61.02 | 42.74 | 36.97 |
| **TLOB** | **74.7** | **61.74** | **48.54** | **41.49** |

**An√°lisis:**
- Mejora promedio de **+1.1% en F1-score** sobre baselines
- Dataset m√°s reciente (2023) con alta volatilidad
- TLOB supera consistentemente a MLPLOB en **todos los horizontes**
- Diferencia m√°s notable en horizontes largos (~5% en h=50, h=100)

### An√°lisis Temporal: Eficiencia de Mercado Creciente

**Intel 2012 vs 2015 (h = 50):**

| Periodo | F1-Score (%) |
|---------|--------------|
| INTC 2012 | **66.87** |
| INTC 2015 | 60.19 |
| **Decline** | **-6.68** |

**Conclusi√≥n:** Confirmaci√≥n emp√≠rica de que los mercados se vuelven m√°s eficientes con el tiempo, dificultando la predicci√≥n. Los patrones predictivos se erosionan a medida que son descubiertos y explotados por traders.

### Threshold Basado en Spread (Tesla)

**F1-Score (%) con Œ∏ = promedio del spread:**

| Horizonte | F1-Score (%) |
|-----------|--------------|
| h = 50 | 41.39 |
| h = 100 | 36.48 |
| h = 200 | 30.82 |

**Conclusi√≥n:** Definir el threshold basado en costos de transacci√≥n (spread) en lugar de balance de clases deteriora significativamente el performance, evidenciando el **gap cr√≠tico entre m√©tricas acad√©micas y profitabilidad pr√°ctica**.

### Ablation Study: Importancia de Dual Attention

**F1-Score (%) en FI-2010:**

| Modelo | h = 10 | h = 20 | h = 50 | h = 100 |
|--------|--------|--------|--------|---------|
| TLOB w/o Spatial Attention | 79.59 | 78.96 | 87.51 | 91.40 |
| TLOB w/o Temporal Attention | 80.27 | 79.20 | 87.72 | 91.42 |
| **TLOB Completo** | **81.55** | **82.68** | **90.03** | **92.81** |

**Conclusi√≥n:** El modelo completo con **dual attention (spatial + temporal)** supera consistentemente a las versiones ablated, demostrando que ambos mecanismos capturan informaci√≥n complementaria esencial.

### Tiempo de Inferencia y Par√°metros

**Comparaci√≥n de modelos (batch_size=1):**

| Modelo | Par√°metros | Tiempo (ms) |
|--------|------------|-------------|
| MLP | 10‚Å∂ | 0.08 |
| LSTM [39] | 1.6 √ó 10‚Å¥ | 0.21 |
| CNN [38] | 3.5 √ó 10‚Å¥ | 0.36 |
| CTABL [36] | 1.1 √ó 10‚Å¥ | 0.48 |
| DAIN-MLP [30] | 5.3 √ó 10‚Å¥ | 0.50 |
| CNNLSTM [40] | 2.8 √ó 10‚Åµ | 0.49 |
| AXIALLOB [23] | 2 √ó 10‚Å¥ | 1.91 |
| DLA [18] | 1.2 √ó 10‚Åµ | 0.23 |
| DeepLOB [45] | 1.4 √ó 10‚Åµ | 1.31 |
| BiNCTABL [37] | 1.1 √ó 10‚Å¥ | 0.71 |
| **MLPLOB** | **6.3 √ó 10‚Å∑** | **4.79** |
| **TLOB** | **1 √ó 10‚Å∑** | **2.24** |

**An√°lisis:**
- TLOB tiene m√°s par√°metros que los baselines pero **mantiene tiempo de inferencia competitivo (2.24ms)**
- Velocidad adecuada para aplicaciones de **high-frequency trading**
- Trade-off favorable: Mayor capacidad del modelo por costo computacional moderado

### Observaciones Clave

1. **Horizontes Cortos (h=10, 20):** MLPLOB es suficiente y ligeramente superior
2. **Horizontes Largos (h=50, 100):** TLOB domina gracias a mecanismo de atenci√≥n
3. **Eficiencia de Mercado:** FI-2010 (2010) > BTC (2023) > NASDAQ (2015)
4. **Volatilidad:** Tesla (alta) m√°s dif√≠cil de predecir que Intel (baja)
5. **Transaction Costs:** Cr√≠ticos para profitabilidad real, no capturados por F1-score

---

## üõ†Ô∏è Desarrollo y Extensi√≥n

### Agregar Nuevo Modelo

1. Crear archivo en `src/models/nuevo_modelo.py`
2. Implementar arquitectura compatible
3. Agregar checkpoint en `src/data/checkpoints/NUEVO_MODELO/`
4. Actualizar `app.py` para incluir nuevo modelo en dropdown

### Agregar Nuevo Dataset

1. Crear script de preprocesamiento en `src/preprocessing/nuevo_dataset.py`
2. Implementar reordenamiento y normalizaci√≥n
3. Agregar ejemplos en `src/data/NUEVO_DATASET/`
4. Actualizar `app.py` para cargar nuevos ejemplos

---

## üìä Visualizaciones Disponibles

La aplicaci√≥n Streamlit incluye:

1. **Gr√°fico de Probabilidades**: Barras con las 3 clases
2. **Heatmap de Atenci√≥n**: Visualizaci√≥n de pesos de atenci√≥n
3. **Evoluci√≥n Temporal del LOB**: Serie de tiempo de precios y vol√∫menes
4. **Comparaci√≥n de Modelos**: Tabla comparativa de predicciones

---

## ü§ù Contribuciones

Este proyecto es parte de un trabajo acad√©mico. Para sugerencias o mejoras:

1. Fork del repositorio
2. Crear branch (`git checkout -b feature/mejora`)
3. Commit cambios (`git commit -m 'Add: nueva funcionalidad'`)
4. Push al branch (`git push origin feature/mejora`)
5. Crear Pull Request

---

## üìñ Referencias

### Paper Original

```bibtex
@article{berti2025tlob,
  title={TLOB: A Novel Transformer Model with Dual Attention for Stock Price Trend Prediction with Limit Order Book Data},
  author={Berti, Leonardo and Kasneci, Gjergji},
  journal={arXiv preprint arXiv:2502.15757},
  year={2025}
}
```

### Recursos Adicionales

1. **Attention is All You Need** (Vaswani et al., 2017)
   - [Paper](https://arxiv.org/abs/1706.03762)
   - Base del mecanismo de atenci√≥n

2. **DeepLOB** (Zhang et al., 2019)
   - [Paper](https://arxiv.org/abs/1808.03668)
   - Baseline para comparaci√≥n

3. **FI-2010 Dataset**
   - [Paper](https://arxiv.org/abs/1705.03233)
   - Dataset de referencia en LOB

4. **PyTorch Documentation**
   - [MultiheadAttention](https://pytorch.org/docs/stable/generated/torch.nn.MultiheadAttention.html)
   - [Transformer](https://pytorch.org/docs/stable/generated/torch.nn.Transformer.html)

---

## üìù Licencia

Este proyecto est√° bajo la licencia **MIT**. Ver archivo [`LICENSE`](LICENSE) para m√°s detalles.

---

## üë• Autores

**Proyecto Final - An√°lisis de Series Temporales con Transformers**

- Implementaci√≥n de TLOB
- Despliegue con Docker y Streamlit
- Visualizaci√≥n interactiva
- Documentaci√≥n completa

**Basado en el trabajo de:**
- Leonardo Berti (Sapienza University of Rome)
- Gjergji Kasneci (Technical University of Munich)

---

## üìß Contacto

Para preguntas o sugerencias sobre este proyecto:

- üìß Email: [tu-email@universidad.edu]
- üíº LinkedIn: [Tu perfil]
- üêô GitHub: [github.com/tu-usuario]

---

## üéØ Pr√≥ximos Pasos

- [ ] Agregar soporte para m√°s criptomonedas
- [ ] Implementar inferencia en tiempo real con API de Binance
- [ ] Agregar an√°lisis de uncertainty/confianza
- [ ] Crear dashboard de monitoreo
- [ ] Implementar fine-tuning del modelo

---

**√öltima actualizaci√≥n:** Noviembre 2025  
**Versi√≥n:** 1.0.0

---

<div align="center">

**‚≠ê Si este proyecto te fue √∫til, considera darle una estrella en GitHub ‚≠ê**

Made with ‚ù§Ô∏è using PyTorch, Streamlit, and Docker

</div>
