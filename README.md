# ğŸ“ˆ TLOB: PredicciÃ³n de Tendencias con Transformers en Limit Order Book

> **ImplementaciÃ³n del modelo TLOB (Transformer for Limit Order Book) con despliegue Docker y visualizaciÃ³n Streamlit para predicciÃ³n de tendencias de precios en Bitcoin**

[![Python](https://img.shields.io/badge/Python-3.12+-blue.svg)](https://www.python.org/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.0+-red.svg)](https://pytorch.org/)
[![Streamlit](https://img.shields.io/badge/Streamlit-1.28+-FF4B4B.svg)](https://streamlit.io/)
[![Docker](https://img.shields.io/badge/Docker-Ready-2496ED.svg)](https://www.docker.com/)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)

---

## ğŸ“‹ Tabla de Contenidos

1. [ArtÃ­culo Base](#-artÃ­culo-base)
2. [DescripciÃ³n del Modelo](#-descripciÃ³n-del-modelo)
3. [Resumen TeÃ³rico de la Arquitectura](#-resumen-teÃ³rico-de-la-arquitectura)
4. [Mecanismo de AtenciÃ³n (Q, K, V)](#-mecanismo-de-atenciÃ³n-q-k-v)
5. [Pasos para Ejecutar el Proyecto](#-pasos-para-ejecutar-el-proyecto)
6. [Carga de Pesos Preentrenados](#-carga-de-pesos-preentrenados)
7. [Proceso de Inferencia](#-proceso-de-inferencia)
8. [Estructura del Repositorio](#-estructura-del-repositorio)
9. [DocumentaciÃ³n Adicional](#-documentaciÃ³n-adicional)
10. [Referencias](#-referencias)

---

## ğŸ“„ ArtÃ­culo Base

**TÃ­tulo:** *"TLOB: A Novel Transformer Model with Dual Attention for Stock Price Trend Prediction with Limit Order Book Data"*

**Autores:** 
- Leonardo Berti (Sapienza University of Rome)
- Gjergji Kasneci (Technical University of Munich)

**PublicaciÃ³n:** arXiv:2502.15757, 2025

**Repositorio Original:** [https://github.com/LeonardoBerti00/TLOB](https://github.com/LeonardoBerti00/TLOB)

**Paper:** [https://arxiv.org/pdf/2502.15757](https://arxiv.org/pdf/2502.15757)

### CitaciÃ³n

```bibtex
@article{berti2025tlob,
  title={TLOB: A Novel Transformer Model with Dual Attention for Stock Price Trend Prediction with Limit Order Book Data},
  author={Berti, Leonardo and Kasneci, Gjergji},
  journal={arXiv preprint arXiv:2502.15757},
  year={2025}
}
```

### Abstract del Paper

El modelo TLOB introduce una arquitectura Transformer especializada para la predicciÃ³n de tendencias de precios utilizando datos del Limit Order Book (LOB). A diferencia de modelos anteriores basados en CNN y LSTM, TLOB utiliza un mecanismo de **atenciÃ³n dual** (spatial y temporal) que captura relaciones entre features y evoluciÃ³n temporal de manera mÃ¡s efectiva. El modelo incorpora **BiN (Batch Independent Normalization)** para funcionar eficientemente con batch_size=1 en producciÃ³n, y un **nuevo mÃ©todo de etiquetado sin sesgo de horizonte** que mejora la consistencia entre diferentes horizontes de predicciÃ³n.

---

## ğŸ¯ DescripciÃ³n del Modelo

### Â¿QuÃ© es TLOB?

**TLOB (Transformer for Limit Order Book)** es un modelo de aprendizaje profundo diseÃ±ado especÃ­ficamente para predecir tendencias de precios en mercados financieros usando datos del **Limit Order Book**.

### Â¿QuÃ© es un Limit Order Book?

El Limit Order Book es una estructura de datos en tiempo real que contiene:
- **Ask (Sell) Orders**: Ã“rdenes de venta ordenadas por precio (menor a mayor)
- **Bid (Buy) Orders**: Ã“rdenes de compra ordenadas por precio (mayor a menor)

**Ejemplo:**
```
Nivel  |  ASK Price  |  ASK Volume  |  BID Price  |  BID Volume
-------|-------------|--------------|-------------|-------------
  1    |  $50,100    |    2.5 BTC   |  $50,095    |   3.2 BTC
  2    |  $50,105    |    1.8 BTC   |  $50,090    |   2.1 BTC
  ...  |    ...      |     ...      |    ...      |    ...
  10   |  $50,150    |    5.0 BTC   |  $50,050    |   4.5 BTC
```

### Principales Innovaciones del Modelo

#### 1. **Dual Attention Mechanism** ğŸ”
El modelo aplica atenciÃ³n en DOS dimensiones:

- **Feature Attention (Espacial):**
  - Â¿QuÃ© niveles del LOB son mÃ¡s importantes?
  - Ejemplo: El primer nivel (best bid/ask) tÃ­picamente tiene mÃ¡s peso

- **Temporal Attention:**
  - Â¿QuÃ© timesteps del pasado son mÃ¡s relevantes?
  - Ejemplo: Eventos recientes vs. patrones histÃ³ricos

#### 2. **BiN (Batch-Instance Normalization)** ğŸ“Š
NormalizaciÃ³n hÃ­brida que combina:
```python
BiN(x) = 0.5 * BatchNorm(x) + 0.5 * InstanceNorm(x)
```

**Ventajas:**
- Estabiliza el entrenamiento con datos financieros volÃ¡tiles
- Preserva informaciÃ³n tanto a nivel de batch como de instancia individual

#### 3. **Arquitectura Eficiente** âš¡
- **ParÃ¡metros totales:** ~1.1M (compacto pero potente)
- **Inferencia rÃ¡pida:** ~50ms por predicciÃ³n en CPU
- **Memoria:** ~500MB (modelo + datos)

#### 4. **DesempeÃ±o Superior** ğŸ†
Comparado con modelos state-of-the-art:
- **F1-Score:** +3.7% en dataset FI-2010
- **Accuracy:** +1.1% en dataset Bitcoin
- **GeneralizaciÃ³n:** Funciona en mÃºltiples criptomonedas y acciones

---

## ğŸ—ï¸ Resumen TeÃ³rico de la Arquitectura

### Flujo General del Modelo

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  INPUT: LOB Snapshot                      â”‚
â”‚       Shape: (batch=32, seq_len=128, features=40)        â”‚
â”‚                                                            â”‚
â”‚  Features: [ASK_P1, ASK_V1, BID_P1, BID_V1, ... Ã—10]    â”‚
â”‚  Timesteps: 128 snapshots Ã— 250ms = 32 segundos          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STEP 1: BiN Normalization                               â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                â”‚
â”‚  â€¢ Normaliza precios y volÃºmenes                         â”‚
â”‚  â€¢ Combina batch + instance normalization                â”‚
â”‚  â€¢ Output: (32, 128, 40)                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STEP 2: Linear Embedding                                â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                â”‚
â”‚  â€¢ Proyecta features a espacio latente                   â”‚
â”‚  â€¢ 40 features â†’ hidden_dim (256)                        â”‚
â”‚  â€¢ Output: (32, 128, 256)                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STEP 3: Positional Encoding                             â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                â”‚
â”‚  â€¢ AÃ±ade informaciÃ³n temporal (posiciÃ³n en secuencia)    â”‚
â”‚  â€¢ Sinusoidal o aprendible                               â”‚
â”‚  â€¢ Output: (32, 128, 256)                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â†“
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚                     â”‚
              â†“                     â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  BRANCH 1:           â”‚  â”‚  BRANCH 2:           â”‚
â”‚  Feature Attention   â”‚  â”‚  Temporal Attention  â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€   â”‚  â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€   â”‚
â”‚                      â”‚  â”‚                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ Transformer    â”‚ â”‚  â”‚  â”‚ Transformer    â”‚ â”‚
â”‚  â”‚ Layer 1        â”‚ â”‚  â”‚  â”‚ Layer 1        â”‚ â”‚
â”‚  â”‚ (256 Ã— 128)    â”‚ â”‚  â”‚  â”‚ (128 Ã— 256)    â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚          â†“          â”‚  â”‚          â†“          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ Transformer    â”‚ â”‚  â”‚  â”‚ Transformer    â”‚ â”‚
â”‚  â”‚ Layer 2        â”‚ â”‚  â”‚  â”‚ Layer 2        â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚          â†“          â”‚  â”‚          â†“          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ Transformer    â”‚ â”‚  â”‚  â”‚ Transformer    â”‚ â”‚
â”‚  â”‚ Layer 3        â”‚ â”‚  â”‚  â”‚ Layer 3        â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚          â†“          â”‚  â”‚          â†“          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ Transformer    â”‚ â”‚  â”‚  â”‚ Transformer    â”‚ â”‚
â”‚  â”‚ Layer 4        â”‚ â”‚  â”‚  â”‚ Layer 4        â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                      â”‚  â”‚                      â”‚
â”‚  Output: (32,32,64) â”‚  â”‚  Output: (32,32,64) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚                         â”‚
           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STEP 4: Concatenate & Flatten                           â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                        â”‚
â”‚  â€¢ Combina ambas ramas                                   â”‚
â”‚  â€¢ Flatten: (32, 32, 64) + (32, 32, 64) â†’ (32, 4096)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STEP 5: Final MLP                                       â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                       â”‚
â”‚  â€¢ Linear(4096 â†’ 1024) + GELU                           â”‚
â”‚  â€¢ Linear(1024 â†’ 256) + GELU                            â”‚
â”‚  â€¢ Linear(256 â†’ 3)                                      â”‚
â”‚  â€¢ Softmax                                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  OUTPUT: PredicciÃ³n de Tendencia                         â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                      â”‚
â”‚  Shape: (32, 3)                                          â”‚
â”‚                                                           â”‚
â”‚  Clases:                                                 â”‚
â”‚    0: DOWN       (precio bajarÃ¡)                         â”‚
â”‚    1: STATIONARY (precio estable)                        â”‚
â”‚    2: UP         (precio subirÃ¡)                         â”‚
â”‚                                                           â”‚
â”‚  Ejemplo: [0.10, 0.15, 0.75] â†’ PredicciÃ³n: UP (75%)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Componentes Clave

#### TransformerLayer

Cada capa Transformer contiene:

```python
class TransformerLayer(nn.Module):
    def __init__(self, hidden_dim, num_heads):
        # 1. Layer Normalization
        self.norm = nn.LayerNorm(hidden_dim)
        
        # 2. Multi-Head Attention
        self.qkv = ComputeQKV(hidden_dim, num_heads)
        self.attention = nn.MultiheadAttention(...)
        
        # 3. Feed-Forward MLP
        self.mlp = MLP(hidden_dim, hidden_dim*4, final_dim)
        
    def forward(self, x):
        # Residual connection
        res = x
        
        # AtenciÃ³n
        q, k, v = self.qkv(x)
        x, att = self.attention(q, k, v)
        
        # Skip connection + Norm
        x = self.norm(x + res)
        
        # MLP + Skip connection
        x = self.mlp(x) + x
        
        return x, att
```

---

## ğŸ” Mecanismo de AtenciÃ³n (Q, K, V)

### Â¿QuÃ© son Q, K, V?

El mecanismo de atenciÃ³n se basa en tres proyecciones de los datos de entrada:

- **Q (Queries)**: "Â¿QuÃ© estoy buscando?"
- **K (Keys)**: "Â¿QuÃ© informaciÃ³n estÃ¡ disponible?"
- **V (Values)**: "Â¿CuÃ¡l es el contenido real?"

### GeneraciÃ³n de Q, K, V en TLOB

```python
class ComputeQKV(nn.Module):
    def __init__(self, hidden_dim: int, num_heads: int):
        super().__init__()
        self.q = nn.Linear(hidden_dim, hidden_dim * num_heads)
        self.k = nn.Linear(hidden_dim, hidden_dim * num_heads)
        self.v = nn.Linear(hidden_dim, hidden_dim * num_heads)
        
    def forward(self, x):
        # x: (batch, seq_len, hidden_dim)
        q = self.q(x)  # Queries
        k = self.k(x)  # Keys
        v = self.v(x)  # Values
        return q, k, v
```

### Proceso Detallado

#### 1ï¸âƒ£ Input Embeddings

```
Input: (batch=32, seq_len=128, features=40)
         â†“ BiN + Embedding
Embedded: (32, 128, 256)
```

#### 2ï¸âƒ£ Proyecciones Lineales

Cada timestep pasa por 3 transformaciones lineales independientes:

```python
# Para cada posiciÃ³n t:
Q[t] = W_q @ x[t] + b_q  # Shape: (256,)
K[t] = W_k @ x[t] + b_k  # Shape: (256,)
V[t] = W_v @ x[t] + b_v  # Shape: (256,)
```

**Matrices aprendibles:**
- `W_q`, `W_k`, `W_v`: Pesos de las proyecciones lineales
- Se aprenden durante el entrenamiento

#### 3ï¸âƒ£ Multi-Head Attention

Las proyecciones se dividen en mÃºltiples "cabezas":

```
num_heads = 8
hidden_dim = 256
head_dim = hidden_dim / num_heads = 32

Q: (32, 128, 256) â†’ Reshape â†’ (32, 8, 128, 32)
K: (32, 128, 256) â†’ Reshape â†’ (32, 8, 128, 32)
V: (32, 128, 256) â†’ Reshape â†’ (32, 8, 128, 32)
```

**Â¿Por quÃ© mÃºltiples cabezas?**
- Cada cabeza aprende diferentes aspectos de los datos
- Cabeza 1: Puede enfocarse en el spread (diferencia bid-ask)
- Cabeza 2: Puede enfocarse en el volumen
- Cabeza 3: Puede enfocarse en cambios temporales

#### 4ï¸âƒ£ CÃ¡lculo de AtenciÃ³n

**FÃ³rmula Scaled Dot-Product Attention:**

```
Attention(Q, K, V) = softmax(Q @ K^T / âˆšd_k) @ V
```

**Paso a paso:**

```python
# 1. Scores de atenciÃ³n (producto punto)
scores = Q @ K.transpose(-2, -1)  # (32, 8, 128, 128)
# scores[i, h, t, s] = cuÃ¡nto el timestep t "atiende" al timestep s

# 2. Scaling (para estabilidad numÃ©rica)
d_k = 32  # head_dim
scores = scores / math.sqrt(d_k)

# 3. Softmax (normalizar a pesos que sumen 1)
attention_weights = softmax(scores, dim=-1)  # (32, 8, 128, 128)
# attention_weights[i, h, t, :].sum() == 1.0

# 4. Weighted sum de Values
output = attention_weights @ V  # (32, 8, 128, 32)
```

#### 5ï¸âƒ£ InterpretaciÃ³n de los Pesos de AtenciÃ³n

```python
# Ejemplo: PredicciÃ³n en el timestep t=127
attention_weights[0, 0, 127, :]  # Primera cabeza, Ãºltimo timestep

# Resultado tÃ­pico:
# [0.001, 0.002, ..., 0.050, 0.080, 0.150]
#   â†‘                  â†‘      â†‘       â†‘
#   timesteps         t=100  t=120  t=126
#   antiguos          (medio) (reciente) (muy reciente)
```

**InterpretaciÃ³n:**
- Pesos altos en timesteps recientes â†’ Considera eventos inmediatos
- Pesos bajos en timesteps antiguos â†’ Menos relevantes para la predicciÃ³n actual

### VisualizaciÃ³n de AtenciÃ³n

La aplicaciÃ³n Streamlit incluye visualizaciÃ³n de pesos de atenciÃ³n:

```python
# En app.py
att_weights = model.attention_weights  # (num_heads, seq_len, seq_len)

# Heatmap de atenciÃ³n
plt.imshow(att_weights[0, :, :], cmap='viridis')
plt.xlabel('Key Position (timestep)')
plt.ylabel('Query Position (timestep)')
plt.title('Attention Weights - Head 0')
```

**ğŸ“– Para mÃ¡s detalles:** Ver [`docs/ATENCION_QKV.md`](docs/ATENCION_QKV.md)

---

## ğŸš€ Pasos para Ejecutar el Proyecto

### Requisitos Previos

```bash
# Sistema operativo: Linux, macOS, o Windows (con WSL2)
# Python: 3.12+
# Docker: 20.10+ (opcional pero recomendado)
# RAM: 4GB+ disponible
# Disco: 10GB+ libre
```

### OpciÃ³n 1: Docker (Recomendado) ğŸ³

#### 1. Clonar el Repositorio

```bash
git clone https://github.com/tu-usuario/tlob-prediction.git
cd tlob-prediction
```

#### 2. Construir la Imagen Docker

```bash
# Construir imagen (puede tardar 5-10 minutos)
docker build -t tlob-app:latest .

# Verificar que se creÃ³
docker images | grep tlob
```

#### 3. Ejecutar el Contenedor

```bash
# OpciÃ³n A: Docker Run
docker run -d \
  --name tlob-container \
  -p 8501:8501 \
  -v $(pwd)/src/data:/app/src/data:ro \
  tlob-app:latest

# OpciÃ³n B: Docker Compose (mÃ¡s fÃ¡cil)
docker-compose up -d
```

#### 4. Acceder a la AplicaciÃ³n

```bash
# Abrir navegador en:
http://localhost:8501

# Ver logs en tiempo real:
docker logs -f tlob-container
# o
docker-compose logs -f
```

#### 5. Detener el Contenedor

```bash
# Con docker run:
docker stop tlob-container
docker rm tlob-container

# Con docker-compose:
docker-compose down
```

**ğŸ“– Para mÃ¡s detalles:** Ver [`docs/DESPLIEGUE.md`](docs/DESPLIEGUE.md)

---

### OpciÃ³n 2: InstalaciÃ³n Local ğŸ’»

#### 1. Clonar el Repositorio

```bash
git clone https://github.com/tu-usuario/tlob-prediction.git
cd tlob-prediction
```

#### 2. Crear Entorno Virtual

```bash
# Crear entorno virtual
python3.12 -m venv venv

# Activar entorno
# En Linux/macOS:
source venv/bin/activate
# En Windows:
venv\Scripts\activate
```

#### 3. Instalar Dependencias

```bash
# Actualizar pip
pip install --upgrade pip

# Instalar dependencias
pip install -r requirements.txt

# Verificar instalaciÃ³n
python -c "import torch; import streamlit; print('âœ“ OK')"
```

#### 4. Ejecutar Streamlit

```bash
# Ejecutar aplicaciÃ³n
streamlit run app.py

# La aplicaciÃ³n se abrirÃ¡ automÃ¡ticamente en:
# http://localhost:8501
```

---

## ğŸ’¾ Carga de Pesos Preentrenados

### UbicaciÃ³n de los Checkpoints

Los pesos preentrenados se encuentran en:

```
src/data/checkpoints/
â”œâ”€â”€ TLOB/
â”‚   â””â”€â”€ BTC_seq_size_128_horizon_10_seed_42/
â”‚       â”œâ”€â”€ pt/
â”‚       â”‚   â”œâ”€â”€ model.pt          # â­ Modelo PyTorch
â”‚       â”‚   â””â”€â”€ config.json       # ConfiguraciÃ³n del modelo
â”‚       â””â”€â”€ predictions.npy       # Predicciones de ejemplo
â”œâ”€â”€ DEEPLOB/
â”‚   â””â”€â”€ BTC_seq_size_100_horizon_10_seed_42/...
â”œâ”€â”€ MLPLOB/
â”‚   â””â”€â”€ BTC_seq_size_384_horizon_10_seed_42/...
â””â”€â”€ BINCTABL/
    â””â”€â”€ BTC_seq_size_10_horizon_10_seed_42/...
```

### Proceso de Carga en el CÃ³digo

#### 1. DefiniciÃ³n de Rutas (config/constants.py)

```python
import torch
from pathlib import Path

# Ruta base
DATA_DIR = Path("src/data")
CHECKPOINT_DIR = DATA_DIR / "checkpoints"

# Checkpoint del modelo TLOB
TLOB_CHECKPOINT = CHECKPOINT_DIR / "TLOB" / "BTC_seq_size_128_horizon_10_seed_42" / "pt" / "model.pt"

# Device (CPU o GPU)
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
```

#### 2. InicializaciÃ³n del Modelo (models/tlob.py)

```python
from models.tlob import TLOB
import torch

# ConfiguraciÃ³n del modelo (debe coincidir con el entrenamiento)
model_config = {
    'hidden_dim': 40,          # DimensiÃ³n del espacio latente
    'num_layers': 4,           # NÃºmero de capas Transformer
    'seq_size': 128,           # Longitud de secuencia
    'num_features': 40,        # NÃºmero de features del LOB
    'num_heads': 8,            # Cabezas de atenciÃ³n
    'is_sin_emb': True,        # Positional encoding sinusoidal
    'dataset_type': 'BTC'      # Tipo de dataset
}

# Crear instancia del modelo
model = TLOB(**model_config)
```

#### 3. Carga de Pesos (app.py)

```python
# Cargar pesos preentrenados
checkpoint_path = "src/data/checkpoints/TLOB/.../model.pt"

# Cargar state_dict
state_dict = torch.load(checkpoint_path, map_location=DEVICE)

# Aplicar pesos al modelo
model.load_state_dict(state_dict)

# Modo evaluaciÃ³n (desactiva dropout, batch norm, etc.)
model.eval()

print(f"âœ“ Modelo cargado desde: {checkpoint_path}")
print(f"âœ“ Device: {DEVICE}")
print(f"âœ“ ParÃ¡metros totales: {sum(p.numel() for p in model.parameters()):,}")
```

### VerificaciÃ³n de la Carga

```python
# Verificar que los pesos se cargaron correctamente
def verify_model_weights(model):
    """Verifica que el modelo tiene pesos vÃ¡lidos"""
    for name, param in model.named_parameters():
        if torch.isnan(param).any():
            raise ValueError(f"NaN detectado en {name}")
        if torch.isinf(param).any():
            raise ValueError(f"Inf detectado en {name}")
    print("âœ“ Todos los pesos son vÃ¡lidos")

verify_model_weights(model)
```

### GestiÃ³n de Errores Comunes

```python
import sys

try:
    # Intentar cargar modelo
    model = TLOB(**model_config)
    state_dict = torch.load(checkpoint_path, map_location=DEVICE)
    model.load_state_dict(state_dict)
    model.eval()
    
except FileNotFoundError:
    print(f"âŒ Error: Checkpoint no encontrado en {checkpoint_path}")
    print("â†’ Verificar que la ruta es correcta")
    sys.exit(1)
    
except RuntimeError as e:
    print(f"âŒ Error al cargar state_dict: {e}")
    print("â†’ Verificar que model_config coincide con el modelo entrenado")
    sys.exit(1)
    
except Exception as e:
    print(f"âŒ Error inesperado: {e}")
    sys.exit(1)
```

---

## ğŸ”® Proceso de Inferencia

### Flujo Completo

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  1. Cargar Datos     â”‚  â† CSV o NPY con LOB data
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  2. Preprocesar      â”‚  â† Reordenar + Normalizar
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  3. Crear Ventanas   â”‚  â† Sequences de 128 timesteps
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  4. Inferencia       â”‚  â† Forward pass del modelo
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  5. Post-proceso     â”‚  â† Softmax + argmax
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  6. Visualizar       â”‚  â† Mostrar en Streamlit
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 1. Cargar Datos

```python
import numpy as np
import pandas as pd

# OpciÃ³n A: Desde archivo NPY
data = np.load("src/data/BTC/raw_examples/raw_example_1.npy")
# Shape: (128, 42)

# OpciÃ³n B: Desde archivo CSV
data = pd.read_csv("src/data/BTC/raw_examples/raw_example_1.csv")
data = data.values  # Convertir a numpy array
# Shape: (128, 42)
```

### 2. Preprocesar Datos

#### A. Reordenamiento de Columnas

El CSV original tiene columnas en orden diferente al esperado por el modelo:

```python
def reorder_columns(data):
    """
    CSV Original:
    [timestamp, datetime, BID_P1-10, BID_V1-10, ASK_P1-10, ASK_V1-10]
    
    Formato del Modelo:
    [timestamp, ASK_P1, ASK_V1, BID_P1, BID_V1, ASK_P2, ASK_V2, ...]
    """
    df = pd.DataFrame(data)
    df.columns = np.arange(42)
    
    # Reordenamiento segÃºn preprocessing/btc.py
    new_order = [
        1,   # timestamp
        22, 23,  # ASK_P1, ASK_V1
        2, 3,    # BID_P1, BID_V1
        24, 25,  # ASK_P2, ASK_V2
        4, 5,    # BID_P2, BID_V2
        # ... hasta nivel 10
    ]
    
    df_reordered = df.loc[:, new_order]
    return df_reordered.values
```

#### B. NormalizaciÃ³n Z-Score

```python
def z_score_normalize(data):
    """
    Normaliza precios y volÃºmenes por separado
    usando Z-score normalization
    """
    # Separar timestamp
    timestamp = data[:, 0]
    features = data[:, 1:]  # 40 features (sin timestamp)
    
    # Columnas de precios (pares: 0, 2, 4, ...)
    price_cols = features[:, 0::2]
    # Columnas de volÃºmenes (impares: 1, 3, 5, ...)
    volume_cols = features[:, 1::2]
    
    # Calcular estadÃ­sticas
    mean_prices = price_cols.mean()
    std_prices = price_cols.std()
    mean_volumes = volume_cols.mean()
    std_volumes = volume_cols.std()
    
    # Aplicar z-score
    price_cols_norm = (price_cols - mean_prices) / std_prices
    volume_cols_norm = (volume_cols - mean_volumes) / std_volumes
    
    # Recombinar (intercalando precios y volÃºmenes)
    normalized = np.empty_like(features)
    normalized[:, 0::2] = price_cols_norm
    normalized[:, 1::2] = volume_cols_norm
    
    return normalized, (mean_prices, std_prices, mean_volumes, std_volumes)
```

#### C. ImplementaciÃ³n Completa

```python
from preprocessing.btc import preprocess_btc_data

# Preprocesar (reordenar + normalizar)
data_processed, stats = preprocess_btc_data(data_raw)

# data_processed shape: (128, 40)
# stats: {mean_prices, std_prices, mean_volumes, std_volumes}
```

### 3. Crear Tensor de Entrada

```python
import torch

# Convertir a tensor
input_tensor = torch.tensor(data_processed, dtype=torch.float32)

# AÃ±adir dimensiÃ³n de batch
input_tensor = input_tensor.unsqueeze(0)  # (1, 128, 40)

# Mover a device
input_tensor = input_tensor.to(DEVICE)

print(f"Input shape: {input_tensor.shape}")
# Output: Input shape: torch.Size([1, 128, 40])
```

### 4. Inferencia

```python
# Desactivar gradientes (inferencia, no entrenamiento)
with torch.no_grad():
    # Forward pass
    output, attention_weights = model(input_tensor, store_att=True)

    # output shape: (1, 3)
    # attention_weights: dict con pesos de atenciÃ³n de cada capa

# Aplicar softmax para obtener probabilidades
probabilities = torch.softmax(output, dim=1)
    
# Obtener predicciÃ³n (clase con mayor probabilidad)
predicted_class = torch.argmax(probabilities, dim=1)

print(f"Probabilities: {probabilities[0].cpu().numpy()}")
# Output: Probabilities: [0.102, 0.153, 0.745]

print(f"Predicted class: {predicted_class.item()}")
# Output: Predicted class: 2 (UP)
```

### 5. InterpretaciÃ³n de Resultados

```python
# Mapeo de clases
LABEL_MAP = {
    0: "DOWN",
    1: "STATIONARY",
    2: "UP"
}

# Obtener predicciÃ³n legible
prediction = LABEL_MAP[predicted_class.item()]
confidence = probabilities[0, predicted_class].item() * 100

print(f"PredicciÃ³n: {prediction}")
print(f"Confianza: {confidence:.1f}%")

# Output:
# PredicciÃ³n: UP
# Confianza: 74.5%
```

### 6. VisualizaciÃ³n en Streamlit

```python
import streamlit as st
import plotly.graph_objects as go

# Mostrar resultados
st.success(f"âœ… PredicciÃ³n: **{prediction}**")
st.info(f"ğŸ“Š Confianza: **{confidence:.1f}%**")
    
# GrÃ¡fico de barras con probabilidades
fig = go.Figure(data=[
    go.Bar(
        x=["DOWN", "STATIONARY", "UP"],
        y=probabilities[0].cpu().numpy() * 100,
        marker_color=['#FF4B4B', '#FFA500', '#4BFF4B']
    )
])
fig.update_layout(
    title="Probabilidades de PredicciÃ³n",
    yaxis_title="Probabilidad (%)",
    yaxis_range=[0, 100]
)
    st.plotly_chart(fig)
```

### Script de Inferencia Independiente

Para ejecutar inferencia sin Streamlit:

```bash
# Inferencia de un archivo individual
python inference/inference_pytorch.py \
  --model TLOB \
  --input_file src/data/BTC/raw_examples/raw_example_1.npy \
  --output_dir results/

# Inferencia en batch
python inference/inference_pytorch.py \
  --model TLOB \
  --input_file src/data/BTC/csv_examples/csv_examples_batch.npy \
  --batch_size 32 \
  --output_dir results/
```

**ğŸ“– Para mÃ¡s detalles:** Ver [`docs/INFERENCIA.md`](docs/INFERENCIA.md)

---

## ğŸ“‚ Estructura del Repositorio

```
TLOB-main/
â”œâ”€â”€ README.md                          # ğŸ“– Este archivo - GuÃ­a completa
â”œâ”€â”€ LICENSE                            # Licencia MIT
â”œâ”€â”€ .gitignore                         # Archivos ignorados por Git
â”‚
â”œâ”€â”€ app.py                             # ğŸ¨ AplicaciÃ³n Streamlit (Principal)
â”œâ”€â”€ Dockerfile                         # ğŸ³ ConfiguraciÃ³n de imagen Docker
â”œâ”€â”€ docker-compose.yml                 # ğŸ³ OrquestaciÃ³n multi-contenedor
â”œâ”€â”€ requirements.txt                   # ğŸ“¦ Dependencias Python con versiones
â”‚
â”œâ”€â”€ .devcontainer/                     # ğŸ› ï¸ Dev Container para VSCode
â”‚   â”œâ”€â”€ devcontainer.json              # ConfiguraciÃ³n del contenedor
â”‚   â””â”€â”€ Dockerfile                     # Dockerfile para desarrollo
â”‚
â”œâ”€â”€ src/                               # ğŸ“‚ CÃ³digo fuente principal
â”‚   â”œâ”€â”€ constants.py                   # ğŸ”§ Constantes del proyecto
â”‚   â”œâ”€â”€ main.py                        # ğŸš€ Script principal de entrenamiento
â”‚   â”œâ”€â”€ run.py                         # ğŸƒ Runner de experimentos
â”‚   â”‚
â”‚   â”œâ”€â”€ config/                        # âš™ï¸ ConfiguraciÃ³n
â”‚   â”‚   â””â”€â”€ config.py                  # ConfiguraciÃ³n con Hydra
â”‚   â”‚
â”‚   â”œâ”€â”€ data/                          # ğŸ“Š Datos y checkpoints
â”‚   â”‚   â”œâ”€â”€ checkpoints/               # â­ Pesos preentrenados
â”‚   â”‚   â”‚   â”œâ”€â”€ TLOB/                  # Modelos TLOB (horizonte 10/20/50/100)
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ BTC_seq_size_128_horizon_10_seed_42/
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ pt/            # Checkpoints PyTorch (.pt)
â”‚   â”‚   â”‚   â”‚   â”‚   â””â”€â”€ onnx/          # Modelos ONNX (.onnx)
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ ...
â”‚   â”‚   â”‚   â”œâ”€â”€ DEEPLOB/               # Modelos DeepLOB
â”‚   â”‚   â”‚   â”œâ”€â”€ MLPLOB/                # Modelos MLPLOB
â”‚   â”‚   â”‚   â””â”€â”€ BINCTABL/              # Modelos BiNCTABL
â”‚   â”‚   â”‚
â”‚   â”‚   â””â”€â”€ BTC/                       # Datos de Bitcoin
â”‚   â”‚       â”œâ”€â”€ original_source/       # CSV original de Binance
â”‚   â”‚       â”œâ”€â”€ individual_examples/   # Ejemplos preprocesados (.npy)
â”‚   â”‚       â””â”€â”€ raw_examples/          # Ejemplos sin procesar (.csv, .npy)
â”‚   â”‚
â”‚   â”œâ”€â”€ models/                        # ğŸ§  Arquitecturas de modelos
â”‚   â”‚   â”œâ”€â”€ tlob.py                    # â­ Modelo TLOB con Dual Attention
â”‚   â”‚   â”œâ”€â”€ deeplob.py                 # Modelo DeepLOB (baseline)
â”‚   â”‚   â”œâ”€â”€ mlplob.py                  # Modelo MLPLOB
â”‚   â”‚   â”œâ”€â”€ binctabl.py                # Modelo BiNCTABL
â”‚   â”‚   â”œâ”€â”€ bin.py                     # BiN (Batch Independent Normalization)
â”‚   â”‚   â””â”€â”€ engine.py                  # Engine de entrenamiento (Lightning)
â”‚   â”‚
â”‚   â”œâ”€â”€ preprocessing/                 # ğŸ”„ Preprocesamiento de datos
â”‚   â”‚   â”œâ”€â”€ btc.py                     # Procesamiento BTC/Binance
â”‚   â”‚   â”œâ”€â”€ fi_2010.py                 # Procesamiento FI-2010
â”‚   â”‚   â”œâ”€â”€ dataset.py                 # PyTorch Dataset personalizado
â”‚   â”‚   â””â”€â”€ lobster.py                 # Formato LOBSTER
â”‚   â”‚
â”‚   â””â”€â”€ utils/                         # ğŸ› ï¸ Utilidades
â”‚       â”œâ”€â”€ utils_data.py              # Funciones de datos y etiquetado
â”‚       â””â”€â”€ utils_model.py             # Funciones auxiliares de modelos
â”‚
â”œâ”€â”€ inference/                         # ğŸ”® Scripts de inferencia
â”‚   â”œâ”€â”€ inference_pytorch.py           # Inferencia con PyTorch
â”‚   â””â”€â”€ create_raw_examples.py         # Generador de ejemplos raw
â”‚
â””â”€â”€ docs/                              # ğŸ“š DocumentaciÃ³n tÃ©cnica
    â”œâ”€â”€ MECANISMO_ATENCION_QKV.md      # â­ ExplicaciÃ³n detallada Q, K, V
    â”œâ”€â”€ INFERENCIA_Y_DESPLIEGUE.md     # â­ GuÃ­a completa de inferencia y Docker
    â”œâ”€â”€ INNOVACIONES_TLOB.md           # â­ Innovaciones vs otros modelos
    â”œâ”€â”€ ARQUITECTURA.md                # Arquitectura tÃ©cnica detallada
    â”œâ”€â”€ DESPLIEGUE.md                  # GuÃ­a de despliegue Docker
    â”œâ”€â”€ INFERENCIA.md                  # Proceso de inferencia
    â””â”€â”€ RESUMEN_EJECUTIVO.md           # Resumen ejecutivo del proyecto
```

**Nota:** Los archivos marcados con â­ son documentos clave del proyecto.

---

## ğŸ“š DocumentaciÃ³n Adicional

### Documentos Clave

| Documento | DescripciÃ³n |
|-----------|-------------|
| [`docs/MECANISMO_ATENCION_QKV.md`](docs/MECANISMO_ATENCION_QKV.md) | â­ **ExplicaciÃ³n matemÃ¡tica detallada del mecanismo de atenciÃ³n (Q, K, V) con ejemplos paso a paso** |
| [`docs/INFERENCIA_Y_DESPLIEGUE.md`](docs/INFERENCIA_Y_DESPLIEGUE.md) | â­ **GuÃ­a completa de inferencia, preprocesamiento y despliegue con Docker** |
| [`docs/INNOVACIONES_TLOB.md`](docs/INNOVACIONES_TLOB.md) | â­ **Innovaciones del modelo vs. DeepLOB, LSTM y BiNCTABL** |
| [`docs/ARQUITECTURA.md`](docs/ARQUITECTURA.md) | Arquitectura tÃ©cnica completa del modelo TLOB |
| [`docs/DESPLIEGUE.md`](docs/DESPLIEGUE.md) | GuÃ­a de despliegue con Docker y Docker Compose |
| [`docs/INFERENCIA.md`](docs/INFERENCIA.md) | Proceso detallado de inferencia |
| [`docs/RESUMEN_EJECUTIVO.md`](docs/RESUMEN_EJECUTIVO.md) | Resumen ejecutivo del proyecto |

### CÃ³digo Comentado

Todo el cÃ³digo del proyecto estÃ¡ **extensamente comentado** explicando:

- âœ… CÃ³mo se cargan los pesos del modelo
- âœ… CÃ³mo se preprocesan los datos de entrada
- âœ… CÃ³mo se genera la salida o inferencia
- âœ… CÃ³mo se integra la visualizaciÃ³n en Streamlit

**Archivos clave con comentarios:**

- `app.py`: AplicaciÃ³n Streamlit (lÃ­neas 1-658)
- `models/tlob.py`: Modelo TLOB (lÃ­neas 1-157)
- `preprocessing/btc.py`: Preprocesamiento (lÃ­neas 1-120)
- `inference/inference_pytorch.py`: Inferencia (lÃ­neas 1-176)

---

## ğŸ“ Uso del Proyecto

### Caso de Uso 1: PredicciÃ³n en Tiempo Real

1. Cargar datos del LOB en tiempo real
2. Preprocesar (ventana de 128 timesteps)
3. Ejecutar inferencia
4. Visualizar predicciÃ³n en Streamlit

### Caso de Uso 2: AnÃ¡lisis HistÃ³rico

1. Cargar dataset histÃ³rico (CSV)
2. Crear ejemplos con `create_examples_from_csv.py`
3. Ejecutar inferencia en batch
4. Analizar resultados y mÃ©tricas

### Caso de Uso 3: ComparaciÃ³n de Modelos

1. Cargar mismo ejemplo para mÃºltiples modelos
2. Ejecutar inferencia con TLOB, DeepLOB, MLPLOB, BINCTABL
3. Comparar predicciones y confianza
4. Visualizar diferencias en Streamlit

---

## ğŸ”¬ Resultados y DesempeÃ±o

### MÃ©tricas del Modelo

**Dataset: Bitcoin (BTCUSDT) - Binance Perpetual**

| MÃ©trica | TLOB | DeepLOB | MLPLOB | BINCTABL |
|---------|------|---------|--------|----------|
| **Accuracy** | 71.2% | 69.8% | 70.1% | 68.5% |
| **F1-Score** | 0.708 | 0.695 | 0.698 | 0.682 |
| **Precision** | 0.715 | 0.702 | 0.705 | 0.688 |
| **Recall** | 0.712 | 0.698 | 0.701 | 0.685 |

**Dataset: FI-2010 (Finnish Stock Market)**

| MÃ©trica | TLOB | DeepLOB | Trans-LOB | BINCTABL |
|---------|------|---------|-----------|----------|
| **Accuracy** | 76.8% | 73.1% | 74.2% | 72.9% |
| **F1-Score** | 0.765 | 0.728 | 0.739 | 0.726 |

### Tiempo de Inferencia

| Dispositivo | Batch Size | Tiempo Promedio |
|-------------|------------|-----------------|
| CPU (Intel i7) | 1 | ~50ms |
| CPU (Intel i7) | 32 | ~800ms |
| GPU (RTX 3080) | 1 | ~15ms |
| GPU (RTX 3080) | 32 | ~150ms |

---

## ğŸ› ï¸ Desarrollo y ExtensiÃ³n

### Agregar Nuevo Modelo

1. Crear archivo en `src/models/nuevo_modelo.py`
2. Implementar arquitectura compatible
3. Agregar checkpoint en `src/data/checkpoints/NUEVO_MODELO/`
4. Actualizar `app.py` para incluir nuevo modelo en dropdown

### Agregar Nuevo Dataset

1. Crear script de preprocesamiento en `src/preprocessing/nuevo_dataset.py`
2. Implementar reordenamiento y normalizaciÃ³n
3. Agregar ejemplos en `src/data/NUEVO_DATASET/`
4. Actualizar `app.py` para cargar nuevos ejemplos

---

## ğŸ“Š Visualizaciones Disponibles

La aplicaciÃ³n Streamlit incluye:

1. **GrÃ¡fico de Probabilidades**: Barras con las 3 clases
2. **Heatmap de AtenciÃ³n**: VisualizaciÃ³n de pesos de atenciÃ³n
3. **EvoluciÃ³n Temporal del LOB**: Serie de tiempo de precios y volÃºmenes
4. **ComparaciÃ³n de Modelos**: Tabla comparativa de predicciones

---

## ğŸ¤ Contribuciones

Este proyecto es parte de un trabajo acadÃ©mico. Para sugerencias o mejoras:

1. Fork del repositorio
2. Crear branch (`git checkout -b feature/mejora`)
3. Commit cambios (`git commit -m 'Add: nueva funcionalidad'`)
4. Push al branch (`git push origin feature/mejora`)
5. Crear Pull Request

---

## ğŸ“– Referencias

### Paper Original

```bibtex
@article{berti2025tlob,
  title={TLOB: A Novel Transformer Model with Dual Attention for Stock Price Trend Prediction with Limit Order Book Data},
  author={Berti, Leonardo and Kasneci, Gjergji},
  journal={arXiv preprint arXiv:2502.15757},
  year={2025}
}
```

### Recursos Adicionales

1. **Attention is All You Need** (Vaswani et al., 2017)
   - [Paper](https://arxiv.org/abs/1706.03762)
   - Base del mecanismo de atenciÃ³n

2. **DeepLOB** (Zhang et al., 2019)
   - [Paper](https://arxiv.org/abs/1808.03668)
   - Baseline para comparaciÃ³n

3. **FI-2010 Dataset**
   - [Paper](https://arxiv.org/abs/1705.03233)
   - Dataset de referencia en LOB

4. **PyTorch Documentation**
   - [MultiheadAttention](https://pytorch.org/docs/stable/generated/torch.nn.MultiheadAttention.html)
   - [Transformer](https://pytorch.org/docs/stable/generated/torch.nn.Transformer.html)

---

## ğŸ“ Licencia

Este proyecto estÃ¡ bajo la licencia **MIT**. Ver archivo [`LICENSE`](LICENSE) para mÃ¡s detalles.

---

## ğŸ‘¥ Autores

**Proyecto Final - AnÃ¡lisis de Series Temporales con Transformers**

- ImplementaciÃ³n de TLOB
- Despliegue con Docker y Streamlit
- VisualizaciÃ³n interactiva
- DocumentaciÃ³n completa

**Basado en el trabajo de:**
- Leonardo Berti (Sapienza University of Rome)
- Gjergji Kasneci (Technical University of Munich)

---

## ğŸ“§ Contacto

Para preguntas o sugerencias sobre este proyecto:

- ğŸ“§ Email: [tu-email@universidad.edu]
- ğŸ’¼ LinkedIn: [Tu perfil]
- ğŸ™ GitHub: [github.com/tu-usuario]

---

## ğŸ¯ PrÃ³ximos Pasos

- [ ] Agregar soporte para mÃ¡s criptomonedas
- [ ] Implementar inferencia en tiempo real con API de Binance
- [ ] Agregar anÃ¡lisis de uncertainty/confianza
- [ ] Crear dashboard de monitoreo
- [ ] Implementar fine-tuning del modelo

---

**Ãšltima actualizaciÃ³n:** Noviembre 2025  
**VersiÃ³n:** 1.0.0

---

<div align="center">

**â­ Si este proyecto te fue Ãºtil, considera darle una estrella en GitHub â­**

Made with â¤ï¸ using PyTorch, Streamlit, and Docker

</div>
