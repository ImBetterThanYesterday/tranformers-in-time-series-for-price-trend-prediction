# ğŸ“ˆ TLOB: PredicciÃ³n de Tendencias de Precios con Transformers

> **Despliegue de aplicaciÃ³n interactiva con Streamlit y Docker**

---

## ğŸ“„ ArtÃ­culo Base

**TÃ­tulo:** "TLOB: A Novel Transformer Model with Dual Attention for Price Trend Prediction with Limit Order Book Data"

**Autores:** Leonardo Berti (Sapienza University of Rome), Gjergji Kasneci (Technical University of Munich)

**Repositorio Original:** [TLOB GitHub](https://github.com/lorenzoletizia/TLOB) *(enlace del paper)*

**PublicaciÃ³n:** 2024

---

## ğŸ¯ DescripciÃ³n del Modelo

### Resumen

TLOB es un modelo **Transformer** diseÃ±ado especÃ­ficamente para predecir tendencias de precios usando datos del **Limit Order Book (LOB)**. A diferencia de modelos previos que utilizan arquitecturas complejas (CNNs, RNNs), TLOB demuestra que una arquitectura basada en Transformers con **Dual Attention** supera el estado del arte en mÃºltiples datasets.

###Principales Innovaciones

1. **Dual Attention Mechanism:**
   - **Spatial Attention:** Captura relaciones entre diferentes features del LOB (precios â†” volÃºmenes)
   - **Temporal Attention:** Captura evoluciÃ³n temporal del mercado
   - Permite al modelo adaptarse a la microestructura del mercado

2. **BiN (Batch-Instance Normalization):**
   - NormalizaciÃ³n a nivel de batch e instancia
   - Estabiliza el entrenamiento con datos financieros volÃ¡tiles

3. **Nuevo mÃ©todo de etiquetado:**
   - Elimina el sesgo de horizonte presente en trabajos anteriores
   - Mejora la robustez del modelo

4. **GeneralizaciÃ³n superior:**
   - Funciona en mÃºltiples datasets (FI-2010, LOBSTER, Bitcoin)
   - Supera SoTA en F1-score (+3.7 en FI-2010, +1.1 en BTC)

### AplicaciÃ³n

El modelo predice la **tendencia del precio** en un horizonte futuro fijo (10, 20, 50 o 100 timesteps) clasificando en 3 clases:
- ğŸ“‰ **DOWN:** Tendencia bajista
- â¡ï¸ **STATIONARY:** Precio estable
- ğŸ“ˆ **UP:** Tendencia alcista

---

## ğŸ—ï¸ Arquitectura del Modelo

### Resumen TeÃ³rico

```
INPUT (batch, 128, 40)
  â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. BiN Normalization            â”‚ â† Estabiliza entrenamiento
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. Linear Embedding (40 â†’ 40)   â”‚ â† ProyecciÃ³n a espacio latente
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3. Positional Encoding          â”‚ â† Encoding sinusoidal
â”‚    (Sinusoidal)                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â†“
        â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”
        â†“             â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Branch 1    â”‚ â”‚  Branch 2    â”‚  â† DUAL ATTENTION
â”‚  (Spatial)   â”‚ â”‚  (Temporal)  â”‚     (InnovaciÃ³n clave)
â”‚              â”‚ â”‚              â”‚
â”‚ 4 Layers     â”‚ â”‚ 4 Layers     â”‚
â”‚ Transformer  â”‚ â”‚ Transformer  â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ 4. Concatenate        â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ 5. MLP Final          â”‚ â† ClasificaciÃ³n
    â”‚    (hidden â†’ 3)       â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â†“
          OUTPUT (batch, 3)
      [DOWN, STATIONARY, UP]
```

### Componentes Clave

#### 1. **BiN (Batch-Instance Normalization)**
```python
# Normaliza tanto a nivel de batch como de instancia
# FÃ³rmula: x_norm = (x - Î¼) / (Ïƒ + Îµ)
# Donde Î¼ y Ïƒ se calculan en dos niveles
```

#### 2. **Positional Encoding**
```python
# Encoding sinusoidal para capturar orden temporal
# PE(pos, 2i) = sin(pos / 10000^(2i/d))
# PE(pos, 2i+1) = cos(pos / 10000^(2i/d))
```

#### 3. **Dual Attention**
```python
# Branch 1 (Spatial): Attention sobre features
Q, K, V = Linear(x)
Attention_spatial = Softmax(Q @ K^T / âˆšd) @ V

# Branch 2 (Temporal): Attention sobre timesteps
# Similar pero con dimensiones transpuestas
```

#### 4. **Transformer Layer**
Cada layer contiene:
- Multi-Head Self-Attention
- Layer Normalization
- Feedforward MLP
- Residual Connections

**ParÃ¡metros totales:** 1,135,974 (~1.1M)

---

## ğŸ“¦ Estructura del Proyecto

```
TLOB-main/
â”œâ”€â”€ app.py                          # AplicaciÃ³n Streamlit
â”œâ”€â”€ Dockerfile                      # ConfiguraciÃ³n Docker
â”œâ”€â”€ docker-compose.yml              # OrquestaciÃ³n (opcional)
â”œâ”€â”€ requirements.txt                # Dependencias Python
â”œâ”€â”€ .dockerignore                   # Archivos a excluir de Docker
â”‚
â”œâ”€â”€ models/                         # Arquitecturas de modelos
â”‚   â”œâ”€â”€ tlob.py                     # Modelo TLOB principal
â”‚   â”œâ”€â”€ bin.py                      # BiN Normalization
â”‚   â”œâ”€â”€ mlplob.py                   # MLP auxiliar
â”‚   â””â”€â”€ ...
â”‚
â”œâ”€â”€ data/                           # Datos y checkpoints
â”‚   â”œâ”€â”€ BTC/
â”‚   â”‚   â””â”€â”€ individual_examples/    # 5 ejemplos precargados
â”‚   â”‚       â”œâ”€â”€ example_1.npy       # Ventana LOB (128Ã—40)
â”‚   â”‚       â”œâ”€â”€ example_2.npy
â”‚   â”‚       â”œâ”€â”€ example_3.npy
â”‚   â”‚       â”œâ”€â”€ example_4.npy
â”‚   â”‚       â”œâ”€â”€ example_5.npy
â”‚   â”‚       â””â”€â”€ README.md
â”‚   â”‚
â”‚   â””â”€â”€ checkpoints/
â”‚       â””â”€â”€ TLOB/
â”‚           â””â”€â”€ BTC_seq_size_128_horizon_10_seed_1/
â”‚               â”œâ”€â”€ pt/
â”‚               â”‚   â””â”€â”€ val_loss=0.623_epoch=2.pt  # Pesos del modelo
â”‚               â””â”€â”€ onnx/
â”‚                   â””â”€â”€ val_loss=0.623_epoch=2.onnx
â”‚
â”œâ”€â”€ preprocessing/                  # Scripts de preprocesamiento
â”‚   â”œâ”€â”€ btc.py                      # Preprocesamiento Bitcoin
â”‚   â”œâ”€â”€ dataset.py                  # Dataset PyTorch
â”‚   â””â”€â”€ ...
â”‚
â””â”€â”€ docs/                           # DocumentaciÃ³n completa
    â”œâ”€â”€ knowledge.md
    â”œâ”€â”€ inference_guide.md
    â””â”€â”€ RESUMEN_EJECUTIVO.md
```

---

## ğŸš€ InstalaciÃ³n y EjecuciÃ³n

### OpciÃ³n 1: EjecuciÃ³n con Docker (Recomendado)

#### Paso 1: Clonar el repositorio

```bash
git clone https://github.com/tu-usuario/tlob-prediction.git
cd tlob-prediction
```

#### Paso 2: Construir la imagen Docker

```bash
docker build -t tlob-app .
```

Este comando:
- Lee el `Dockerfile`
- Instala todas las dependencias
- Copia el cÃ³digo fuente
- Configura la aplicaciÃ³n Streamlit

**Tiempo estimado:** 5-10 minutos (primera vez)

#### Paso 3: Ejecutar el contenedor

```bash
docker run -p 8501:8501 tlob-app
```

ParÃ¡metros:
- `-p 8501:8501`: Mapea el puerto 8501 del contenedor al host
- `tlob-app`: Nombre de la imagen

#### Paso 4: Acceder a la aplicaciÃ³n

Abre tu navegador y ve a:
```
http://localhost:8501
```

Â¡La aplicaciÃ³n deberÃ­a estar corriendo! ğŸ‰

---

### OpciÃ³n 2: EjecuciÃ³n Local (Sin Docker)

#### Paso 1: Instalar dependencias

```bash
# Crear entorno virtual (recomendado)
python3 -m venv venv
source venv/bin/activate  # En Windows: venv\Scripts\activate

# Instalar dependencias
pip install -r requirements.txt
pip install streamlit plotly seaborn
```

#### Paso 2: Ejecutar la aplicaciÃ³n

```bash
streamlit run app.py
```

#### Paso 3: Acceder

La aplicaciÃ³n se abrirÃ¡ automÃ¡ticamente en tu navegador, o accede a:
```
http://localhost:8501
```

---

## ğŸ® Uso de la AplicaciÃ³n

### Interfaz Principal

La aplicaciÃ³n tiene 4 pestaÃ±as principales:

#### 1. **ğŸ“Š Datos**
- Visualiza la ventana temporal del LOB en formato heatmap
- Muestra evoluciÃ³n temporal de features clave
- Tabla con valores numÃ©ricos
- EstadÃ­sticas bÃ¡sicas (mean, std, min, max)

#### 2. **ğŸ” AnÃ¡lisis**
- DistribuciÃ³n de valores por feature
- EstadÃ­sticas detalladas (percentiles, cuartiles)
- AnÃ¡lisis visual de patrones

#### 3. **ğŸ¯ PredicciÃ³n**
- BotÃ³n para ejecutar inferencia
- Carga del modelo TLOB
- Forward pass sobre los datos

#### 4. **ğŸ“ˆ Resultados**
- PredicciÃ³n final con emoji visual
- Confianza de la predicciÃ³n
- DistribuciÃ³n de probabilidades (grÃ¡fico de barras)
- Logits y probabilidades detalladas
- InterpretaciÃ³n del resultado

### Flujo de Uso

```
1. Seleccionar ejemplo precargado (o subir archivo .npy)
   â†“
2. Explorar datos en pestaÃ±a "Datos"
   â†“
3. Analizar estadÃ­sticas en "AnÃ¡lisis"
   â†“
4. Ir a "PredicciÃ³n" y hacer clic en "Ejecutar PredicciÃ³n"
   â†“
5. Ver resultados en "Resultados"
```

---

## ğŸ”§ CÃ³mo Funciona la Inferencia

### 1. Carga de Pesos del Modelo

```python
# app.py - FunciÃ³n load_model()

# Paso 1: Instanciar arquitectura
model = TLOB(**MODEL_CONFIG)

# Paso 2: Cargar checkpoint (.pt)
checkpoint = torch.load(CHECKPOINT_PATH, map_location=DEVICE, weights_only=False)

# Paso 3: Limpiar state_dict (remover prefijo "model.")
# PyTorch Lightning guarda con este prefijo
state_dict = checkpoint["state_dict"]
new_state_dict = {}
for key, value in state_dict.items():
    if key.startswith("model."):
        new_key = key[6:]  # Remover prefijo
        new_state_dict[new_key] = value

# Paso 4: Cargar pesos en el modelo
model.load_state_dict(new_state_dict)

# Paso 5: Modo evaluaciÃ³n
model.eval()  # Desactiva dropout, batch norm, etc.
```

**Checkpoint usado:** `val_loss=0.623_epoch=2.pt`
- Mejor modelo del entrenamiento (epoch 2)
- Validation loss: 0.623
- Horizonte de predicciÃ³n: 10 timesteps
- Entrenado en Bitcoin LOB (Enero 2023)

---

### 2. Preprocesamiento de Datos

```python
# app.py - FunciÃ³n load_lob_window()

# Los datos ya vienen preprocesados:
# - NormalizaciÃ³n Z-score: (x - Î¼) / Ïƒ
# - Shape: (128, 40)
# - 128 timesteps consecutivos
# - 40 features del LOB

window = np.load(file_path)  # Cargar desde archivo

# Validar shape
assert window.shape == (128, 40), "Shape incorrecto"

# Estructura de features:
# 0-9:   ASK Prices (10 niveles)
# 10-19: ASK Volumes
# 20-29: BID Prices
# 30-39: BID Volumes
```

**Nota importante:** Los datos **ya estÃ¡n normalizados**. No se requiere preprocesamiento adicional.

---

### 3. GeneraciÃ³n de la Salida (Inferencia)

```python
# app.py - FunciÃ³n predict()

def predict(model, window):
    # Paso 1: AÃ±adir dimensiÃ³n de batch
    # (128, 40) â†’ (1, 128, 40)
    X = np.expand_dims(window, axis=0)
    
    # Paso 2: Convertir a tensor PyTorch
    X_tensor = torch.from_numpy(X).float().to(DEVICE)
    
    # Paso 3: Inferencia (sin calcular gradientes)
    with torch.no_grad():
        # Forward pass del modelo
        logits = model(X_tensor)  # Shape: (1, 3)
        
        # Aplicar softmax para obtener probabilidades
        # Softmax: e^x_i / sum(e^x_j)
        probs = F.softmax(logits, dim=1)  # Shape: (1, 3)
        
        # Clase predicha (argmax)
        pred = torch.argmax(probs, dim=1)  # Shape: (1,)
    
    # Paso 4: Convertir a NumPy y extraer valores
    return (
        logits[0].cpu().numpy(),  # [logit_down, logit_stat, logit_up]
        probs[0].cpu().numpy(),   # [p_down, p_stat, p_up]
        pred[0].item()            # 0, 1, o 2
    )
```

**Flujo interno del modelo:**
1. **Input:** `(1, 128, 40)`
2. **BiN Normalize:** NormalizaciÃ³n dual
3. **Embed:** Linear (40 â†’ 40)
4. **Add Pos Encoding:** `+ sinusoidal_encoding`
5. **Dual Attention:**
   - Branch 1 (Spatial): 4 layers Transformer
   - Branch 2 (Temporal): 4 layers Transformer
6. **Concatenate:** Unir ambas ramas
7. **MLP Final:** `hidden*2 â†’ hidden â†’ 3`
8. **Output:** `(1, 3)` logits

---

### 4. IntegraciÃ³n con Streamlit

```python
# app.py - VisualizaciÃ³n de resultados

# Paso 1: Ejecutar predicciÃ³n
logits, probs, pred = predict(model, window)

# Paso 2: Mapear a etiquetas
pred_label = CLASS_LABELS[pred]  # "DOWN", "STATIONARY", "UP"
pred_emoji = CLASS_EMOJIS[pred]  # ğŸ“‰, â¡ï¸, ğŸ“ˆ
confidence = probs[pred]          # Probabilidad de la clase predicha

# Paso 3: Visualizar
st.markdown(f"""
<div style="...">
    <h1>{pred_emoji}</h1>
    <h2>{pred_label}</h2>
    <h3>Confianza: {confidence:.2%}</h3>
</div>
""", unsafe_allow_html=True)

# Paso 4: GrÃ¡fico de probabilidades
fig = go.Figure(data=[
    go.Bar(x=["DOWN", "STATIONARY", "UP"], y=probs*100)
])
st.plotly_chart(fig)

# Paso 5: Detalles tÃ©cnicos
st.code(f"""
Logits: [{logits[0]:.4f}, {logits[1]:.4f}, {logits[2]:.4f}]
Probabilidades: [{probs[0]:.2%}, {probs[1]:.2%}, {probs[2]:.2%}]
PredicciÃ³n: {pred_label} (clase {pred})
""")
```

**Componentes de visualizaciÃ³n:**
- Resultado principal con color dinÃ¡mico
- MÃ©tricas de las 3 clases
- GrÃ¡fico interactivo de probabilidades (Plotly)
- Heatmap de la ventana temporal
- EvoluciÃ³n temporal de features clave
- EstadÃ­sticas detalladas

---

## ğŸ“Š Ejemplos Precargados

La aplicaciÃ³n incluye **5 ejemplos** listos para usar:

| Archivo | PredicciÃ³n | Confianza | InterpretaciÃ³n |
|---------|------------|-----------|----------------|
| `example_1.npy` | â¡ï¸ STATIONARY | 92.06% | Precio estable con alta confianza |
| `example_2.npy` | ğŸ“ˆ UP | 55.15% | Tendencia alcista moderada |
| `example_3.npy` | ğŸ“ˆ UP | 93.81% | Tendencia alcista muy fuerte |
| `example_4.npy` | â¡ï¸ STATIONARY | 77.45% | Precio estable |
| `example_5.npy` | ğŸ“‰ DOWN | 86.90% | Tendencia bajista fuerte |

Cada ejemplo es una ventana de **128 timesteps Ã— 40 features** extraÃ­da del dataset de Bitcoin.

---

## ğŸ³ Comandos Docker Ãštiles

```bash
# Construir imagen
docker build -t tlob-app .

# Ejecutar contenedor
docker run -p 8501:8501 tlob-app

# Ejecutar en modo detached (background)
docker run -d -p 8501:8501 tlob-app

# Ver logs
docker logs <container_id>

# Detener contenedor
docker stop <container_id>

# Listar contenedores activos
docker ps

# Listar todas las imÃ¡genes
docker images

# Eliminar contenedor
docker rm <container_id>

# Eliminar imagen
docker rmi tlob-app

# Acceder al contenedor (debug)
docker exec -it <container_id> /bin/bash
```

---

## ğŸ”¬ Detalles TÃ©cnicos

### Requisitos de Sistema

- **Python:** 3.9+
- **RAM:** MÃ­nimo 4GB (recomendado 8GB)
- **Disco:** ~2GB para imagen Docker
- **CPU:** Cualquier procesador moderno
- **GPU:** Opcional (el modelo funciona bien en CPU)

### Dependencias Principales

```
torch==2.0.1
pytorch-lightning==2.0.0
streamlit==1.28.0
plotly==5.17.0
numpy==1.24.0
pandas==2.0.0
einops==0.7.0
```

### Performance

- **Latencia de inferencia:** ~50-100ms por predicciÃ³n (CPU)
- **Throughput:** ~10-20 predicciones/segundo
- **TamaÃ±o del modelo:** ~4.5 MB (.pt) o ~4.3 MB (.onnx)

---

## ğŸ“š DocumentaciÃ³n Adicional

Para mÃ¡s detalles, consulta:

- **`docs/knowledge.md`:** Knowledge base completa del proyecto
- **`docs/inference_guide.md`:** GuÃ­a detallada de inferencia
- **`docs/RESUMEN_EJECUTIVO.md`:** Resumen ejecutivo
- **`data/BTC/individual_examples/README.md`:** DocumentaciÃ³n de ejemplos

---

## ğŸ¤ Contribuciones

Este proyecto es una implementaciÃ³n educativa del paper TLOB para el curso de AnalÃ­tica.

**Equipo:**
- [Tu nombre]
- [Nombre compaÃ±ero 1]
- [Nombre compaÃ±ero 2]

**Instructor:** [Nombre del profesor]  
**Curso:** AnalÃ­tica Avanzada  
**Universidad:** [Tu universidad]  
**Fecha:** Noviembre 2025

---

## ğŸ“„ Licencia

Este proyecto estÃ¡ basado en el repositorio original TLOB, sujeto a su licencia.

---

## ğŸ™ Agradecimientos

- **Autores del paper TLOB:** Leonardo Berti y Gjergji Kasneci
- **Dataset:** Bitcoin LOB de Kaggle
- **Frameworks:** PyTorch, PyTorch Lightning, Streamlit

---

## ğŸ“ Contacto

Para preguntas o problemas:
- Abrir un issue en GitHub
- Contactar al equipo: [email]

---

**Â¡Gracias por usar TLOB! ğŸš€**


